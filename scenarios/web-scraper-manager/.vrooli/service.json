{
  "$schema": "../../../../.vrooli/schemas/service.schema.json",
  "version": "1.0.0",
  "service": {
    "name": "web-scraper-manager",
    "displayName": "Web Scraper Manager",
    "description": "Unified dashboard for managing web scraping across multiple platforms (Huginn, Browserless, Agent-S2) with orchestrated workflows and data export",
    "version": "1.0.0",
    "tags": [
      "business-application",
      "data-collection",
      "web-scraping",
      "automation",
      "multi-platform",
      "custom-ui",
      "orchestration",
      "export",
      "monitoring",
      "go-api",
      "node-ui",
      "postgres-storage",
      "redis-cache",
      "qdrant-vectors",
      "minio-storage",
      "ollama-ai"
    ]
  },
  "ports": {
    "api": {
      "env_var": "API_PORT",
      "description": "Web scraper manager coordination API port",
      "range": "15000-19999"
    },
    "ui": {
      "env_var": "UI_PORT",
      "description": "Web scraper manager UI dashboard port",
      "range": "35000-39999"
    }
  },
  "lifecycle": {
    "version": "2.0.0",
    "health": {
      "description": "Web Scraper Manager health check configuration",
      "endpoints": {
        "api": "/health",
        "ui": "/health"
      },
      "checks": [
        {
          "name": "api_endpoint",
          "type": "http",
          "target": "http://localhost:${API_PORT}/health",
          "critical": true,
          "timeout": 5000,
          "interval": 30000
        },
        {
          "name": "ui_endpoint",
          "type": "http",
          "target": "http://localhost:${UI_PORT}/health",
          "critical": false,
          "timeout": 3000,
          "interval": 45000
        }
      ],
      "timeout": 5000,
      "interval": 30000,
      "startup_grace_period": 10000
    },
    "setup": {
      "description": "Initialize Web Scraper Manager",
      "condition": {
        "checks": [
          {
            "type": "binaries",
            "targets": [
              "api/web-scraper-manager-api",
              "web-scraper-manager"
            ]
          },
          {
            "type": "ui-bundle",
            "bundle_path": "ui/dist/index.html",
            "source_dir": "ui/src"
          },
          {
            "type": "cli",
            "command": "web-scraper-manager",
            "targets": [
              "web-scraper-manager"
            ]
          },
          {
            "type": "resources",
            "populated": true
          }
        ]
      },
      "steps": [
        {
          "name": "base-setup",
          "run": "bash ../../scripts/lib/setup.sh",
          "description": "Execute generic setup (e.g. network, system, git)"
        },
        {
          "name": "add-data",
          "run": "../../scripts/resources/populate/populate.sh .",
          "description": "Add app data to resources"
        },
        {
          "name": "setup-storage-buckets",
          "run": "bash scripts/lib/setup-minio-buckets.sh",
          "description": "Create MinIO buckets for scraped content"
        },
        {
          "name": "setup-vector-collections",
          "run": "bash scripts/lib/setup-qdrant-collections.sh",
          "description": "Initialize Qdrant collections for content similarity",
          "condition": {
            "resource_enabled": "qdrant"
          }
        },
        {
          "name": "load-platform-configs",
          "run": "bash scripts/lib/load-platform-configs.sh",
          "description": "Load platform capability configurations into database"
        },
        {
          "name": "install-cli",
          "run": "cd cli && ./install.sh",
          "description": "Install CLI command globally"
        },
        {
          "name": "build-api",
          "run": "cd api && go mod download && go build -o web-scraper-manager-api .",
          "description": "Build Go coordination API binary"
        },
        {
          "name": "install-ui-deps",
          "run": "cd ui && npm install",
          "description": "Install UI dependencies",
          "condition": {
            "file_exists": "ui/package.json"
          }
        },
        {
          "name": "build-ui",
          "run": "cd ui && npm run build",
          "description": "Build production UI bundle"
        },
        {
          "name": "show-urls",
          "run": "echo 'ðŸš€ Web Scraper Manager initialized\\n  Dashboard: http://localhost:${UI_PORT}\\n  API: http://localhost:${API_PORT}\\n  CLI: web-scraper-manager --help'",
          "description": "Display service access URLs"
        }
      ]
    },
    "develop": {
      "description": "Start web scraper manager with Go API server",
      "steps": [
        {
          "name": "start-api",
          "run": "cd api && ./web-scraper-manager-api",
          "description": "Start Go API server in background",
          "background": true,
          "condition": {
            "file_exists": "api/web-scraper-manager-api"
          }
        },
        {
          "name": "start-ui",
          "run": "cd ui && node server.js",
          "description": "Start Node.js UI server in background",
          "background": true,
          "condition": {
            "file_exists": "ui/dist/index.html"
          }
        },
        {
          "name": "initialize-redis-queues",
          "run": "bash scripts/lib/initialize-redis-queues.sh",
          "description": "Initialize Redis job queues"
        },
        {
          "name": "show-urls",
          "run": "echo 'ðŸš€ Web Scraper Manager running:\\n  Dashboard: http://localhost:$UI_PORT\\n  API: http://localhost:$API_PORT\\n  MinIO: http://localhost:${RESOURCE_PORTS[minio]}\\n  CLI: web-scraper-manager --help'",
          "description": "Display all running service URLs"
        }
      ]
    },
    "test": {
      "description": "Test web scraper manager using phased testing architecture",
      "steps": [
        {
          "name": "run-phased-tests",
          "run": "bash test/run-tests.sh",
          "description": "Run all test phases (structure, dependencies, unit, api, integration, business, performance)"
        }
      ]
    },
    "stop": {
      "description": "Stop services",
      "steps": [
        {
          "name": "stop-api",
          "run": "pkill -f \"web-scraper-manager-api\" || true; sleep 1; pkill -9 -f \"web-scraper-manager-api\" 2>/dev/null || true",
          "description": "Stop API process"
        },
        {
          "name": "stop-ui",
          "run": "pkill -f \"scenarios/web-scraper-manager.*server\\.js\" || true; sleep 1; pkill -9 -f \"scenarios/web-scraper-manager.*server\\.js\" 2>/dev/null || true",
          "description": "Stop UI process"
        }
      ]
    }
  },
  "dependencies": {
    "resources": {
      "postgres": {
        "type": "postgres",
        "enabled": true,
        "required": true,
        "purpose": "Store scraping agent configurations, results, metrics, and orchestration metadata",
        "initialization": [
          {
            "file": "initialization/storage/postgres/schema.sql",
            "type": "schema"
          }
        ]
      },
      "minio": {
        "type": "minio",
        "enabled": true,
        "required": true,
        "purpose": "Store scraped assets, screenshots, and exported data files"
      },
      "qdrant": {
        "type": "qdrant",
        "enabled": true,
        "required": false,
        "purpose": "Vector database for content similarity detection and duplicate removal"
      },
      "redis": {
        "type": "redis",
        "enabled": true,
        "required": true,
        "purpose": "Job queues and caching for scraping orchestration"
      },
      "ollama": {
        "type": "ollama",
        "enabled": true,
        "required": false,
        "purpose": "AI models for intelligent content extraction and analysis",
        "models": [
          "llama3.2",
          "nomic-embed-text"
        ]
      },
      "huginn": {
        "type": "external-service",
        "enabled": false,
        "required": false,
        "purpose": "RSS/social media monitoring and scheduled scraping",
        "default_port": 4111,
        "health_endpoint": "/agents"
      },
      "browserless": {
        "type": "external-service",
        "enabled": false,
        "required": false,
        "purpose": "JavaScript-heavy sites, screenshots, PDF generation",
        "default_port": 4110,
        "health_endpoint": "/stats"
      },
      "agent-s2": {
        "type": "external-service",
        "enabled": false,
        "required": false,
        "purpose": "AI-powered web interaction and complex scraping",
        "default_port": 4113,
        "health_endpoint": "/health"
      }
    }
  }
}
{
  "name": "foliage-predictor",
  "nodes": [
    {
      "parameters": {},
      "id": "webhook-trigger",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [250, 300],
      "webhookId": "foliage-predictor-webhook"
    },
    {
      "parameters": {},
      "id": "manual-trigger",
      "name": "Manual Trigger",
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [250, 100]
    },
    {
      "parameters": {
        "values": {
          "string": [
            {
              "name": "region_id",
              "value": "={{ $json.region_id || '1' }}"
            }
          ]
        }
      },
      "id": "set-defaults",
      "name": "Set Defaults",
      "type": "n8n-nodes-base.set",
      "typeVersion": 1,
      "position": [450, 100]
    },
    {
      "parameters": {
        "command": "psql -h ${service.postgres.host} -p ${service.postgres.port} -U ${service.postgres.user} -d ${service.postgres.database} -t -A -c \"SELECT json_build_object('region', json_build_object('id', r.id, 'name', r.name, 'state', r.state, 'typical_peak_week', r.typical_peak_week), 'recent_weather', (SELECT json_agg(json_build_object('date', date, 'high', temperature_high_c, 'low', temperature_low_c, 'precip', precipitation_mm)) FROM weather_data WHERE region_id = r.id AND date >= CURRENT_DATE - INTERVAL '14 days' ORDER BY date DESC), 'historical_observations', (SELECT json_agg(json_build_object('date', observation_date, 'status', peak_status, 'intensity', color_intensity)) FROM foliage_observations WHERE region_id = r.id AND observation_date >= CURRENT_DATE - INTERVAL '1 year' ORDER BY observation_date DESC LIMIT 30)) FROM regions r WHERE r.id = {{ $json.region_id }};\""
      },
      "id": "get-region-context",
      "name": "Get Region Context",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [650, 200]
    },
    {
      "parameters": {
        "functionCode": "// Prepare Ollama prompt with context data\nconst context = $input.first().json;\nconst prompt = `You are a foliage prediction expert. Based on the following data, predict when fall foliage will peak and provide a confidence score (0-1).\n\nRegion: ${context.region.name}, ${context.region.state}\nTypical peak week: Week ${context.region.typical_peak_week} of the year\n\nRecent weather (last 14 days):\n${JSON.stringify(context.recent_weather, null, 2)}\n\nHistorical observations:\n${JSON.stringify(context.historical_observations, null, 2)}\n\nProvide your prediction in JSON format:\n{\n  \"predicted_peak_date\": \"YYYY-MM-DD\",\n  \"confidence_score\": 0.0-1.0,\n  \"peak_window_start\": \"YYYY-MM-DD\",\n  \"peak_window_end\": \"YYYY-MM-DD\",\n  \"factors\": [\n    \"list of key factors influencing prediction\"\n  ],\n  \"foliage_progression\": \"not_started|progressing|near_peak|peak|past_peak\"\n}`;\n\nreturn {\n  prompt: prompt,\n  model: 'llama3.2:3b',\n  type: 'reasoning',\n  quiet: true,\n  context_data: context\n};"
      },
      "id": "prepare-ollama-request",
      "name": "Prepare Ollama Request",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [850, 200]
    },
    {
      "parameters": {
        "command": "# Save prompt to temp file to handle complex JSON formatting\ntemp_file=\"/tmp/ollama_prompt_$(date +%s)_$RANDOM.txt\"\necho '{{ $json.prompt }}' > \"$temp_file\"\n\n# Call Ollama CLI with the prompt from file\nresult=$(vrooli resource ollama generate \"$(cat \"$temp_file\")\" --model '{{ $json.model }}' --type '{{ $json.type }}' {{ $json.quiet ? '--quiet' : '' }})\n\n# Clean up temp file\nrm -f \"$temp_file\"\n\n# Output the result\necho \"$result\""
      },
      "id": "call-ollama",
      "name": "Call Ollama CLI",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [1050, 200]
    },
    {
      "parameters": {
        "functionCode": "// Parse response from Ollama CLI\nconst ollamaResult = $input.first().json;\nconst context = $node['prepare-ollama-request'].json.context_data;\n\n// Parse the AI response from stdout\nlet prediction;\ntry {\n  // The CLI output is in stdout field\n  const responseText = ollamaResult.stdout || ollamaResult;\n  // Extract JSON from the response (might have extra text)\n  const jsonMatch = responseText.match(/\\{[\\s\\S]*\\}/m);\n  if (!jsonMatch) {\n    throw new Error('No JSON found in response');\n  }\n  prediction = JSON.parse(jsonMatch[0]);\n} catch (error) {\n  throw new Error('Failed to parse prediction JSON: ' + error.message + ' Response: ' + JSON.stringify(ollamaResult));\n}\n\nreturn {\n  region_id: context.region.id,\n  predicted_peak_date: prediction.predicted_peak_date,\n  confidence_score: prediction.confidence_score,\n  peak_window_start: prediction.peak_window_start,\n  peak_window_end: prediction.peak_window_end,\n  factors: prediction.factors,\n  foliage_progression: prediction.foliage_progression\n};"
      },
      "id": "parse-prediction",
      "name": "Parse Prediction",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1250, 200]
    },
    {
      "parameters": {
        "command": "psql -h ${service.postgres.host} -p ${service.postgres.port} -U ${service.postgres.user} -d ${service.postgres.database} -c \"INSERT INTO foliage_predictions (region_id, prediction_date, predicted_peak_date, confidence_score, model_version, factors) VALUES ({{ $json.region_id }}, CURRENT_DATE, '{{ $json.predicted_peak_date }}', {{ $json.confidence_score }}, 'ollama-llama3.2', '{{ $json.factors }}');\""
      },
      "id": "store-prediction",
      "name": "Store Prediction",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [1450, 200]
    },
    {
      "parameters": {
        "command": "psql -h ${service.postgres.host} -p ${service.postgres.port} -U ${service.postgres.user} -d ${service.postgres.database} -c \"INSERT INTO foliage_observations (region_id, observation_date, peak_status, source) VALUES ({{ $json.region_id }}, CURRENT_DATE, '{{ $json.foliage_progression }}', 'predicted') ON CONFLICT (region_id, observation_date, source) DO UPDATE SET peak_status = EXCLUDED.peak_status;\""
      },
      "id": "update-status",
      "name": "Update Current Status",
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [1650, 200]
    },
    {
      "parameters": {
        "values": {
          "string": [
            {
              "name": "status",
              "value": "success"
            }
          ],
          "object": [
            {
              "name": "prediction",
              "value": "={{ $json }}"
            }
          ]
        }
      },
      "id": "format-response",
      "name": "Format Response",
      "type": "n8n-nodes-base.set",
      "typeVersion": 1,
      "position": [1650, 200]
    }
  ],
  "connections": {
    "manual-trigger": {
      "main": [
        [
          {
            "node": "set-defaults",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "webhook-trigger": {
      "main": [
        [
          {
            "node": "get-region-context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "set-defaults": {
      "main": [
        [
          {
            "node": "get-region-context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "get-region-context": {
      "main": [
        [
          {
            "node": "prepare-ollama-request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "prepare-ollama-request": {
      "main": [
        [
          {
            "node": "call-ollama",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "call-ollama": {
      "main": [
        [
          {
            "node": "parse-prediction",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "parse-prediction": {
      "main": [
        [
          {
            "node": "store-prediction",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "store-prediction": {
      "main": [
        [
          {
            "node": "update-status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "update-status": {
      "main": [
        [
          {
            "node": "format-response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "id": "foliage-predictor"
}
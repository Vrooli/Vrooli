{
  "name": "Chat RAG - Conversational Research Assistant",
  "nodes": [
    {
      "parameters": {
        "path": "chat-message",
        "httpMethod": "POST",
        "responseMode": "onReceived",
        "options": {}
      },
      "id": "chat-webhook",
      "name": "Chat Message Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [240, 300],
      "webhookId": "chat-message"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Process incoming chat message\nconst body = $input.item.json.body;\n\n// Validate required fields\nif (!body.message) {\n  throw new Error('Message is required');\n}\n\nconst request = {\n  message_id: body.message_id || crypto.randomUUID(),\n  conversation_id: body.conversation_id || crypto.randomUUID(),\n  user_id: body.user_id || 'default-user',\n  organization: body.organization || 'default',\n  message: body.message.trim(),\n  timestamp: new Date().toISOString(),\n  processing_start: Date.now()\n};\n\n// Detect if this is a special command\nconst message = request.message.toLowerCase();\nrequest.is_command = false;\nrequest.command_type = null;\nrequest.command_params = {};\n\n// Command detection patterns\nif (message.includes('generate report') || message.includes('create report') || message.includes('new report')) {\n  request.is_command = true;\n  request.command_type = 'generate_report';\n  \n  // Extract topic from message\n  const topicMatch = message.match(/(?:report on|report about|research)\\s+([^.!?]+)/i);\n  if (topicMatch) {\n    request.command_params.topic = topicMatch[1].trim();\n  }\n  \n  // Extract depth\n  if (message.includes('deep')) {\n    request.command_params.depth = 'deep';\n  } else if (message.includes('quick')) {\n    request.command_params.depth = 'quick';\n  } else {\n    request.command_params.depth = 'standard';\n  }\n  \n  // Extract length\n  const lengthMatch = message.match(/(\\d+)\\s*page/);\n  if (lengthMatch) {\n    request.command_params.target_length = Math.max(1, Math.min(10, parseInt(lengthMatch[1])));\n  } else {\n    request.command_params.target_length = 5;\n  }\n}\n\nelse if (message.includes('schedule') && (message.includes('report') || message.includes('daily') || message.includes('weekly'))) {\n  request.is_command = true;\n  request.command_type = 'schedule_report';\n  \n  // Extract frequency\n  if (message.includes('daily')) {\n    request.command_params.frequency = 'daily';\n  } else if (message.includes('weekly')) {\n    request.command_params.frequency = 'weekly';\n  } else if (message.includes('monthly')) {\n    request.command_params.frequency = 'monthly';\n  }\n}\n\nelse if (message.includes('export') && message.includes('pdf')) {\n  request.is_command = true;\n  request.command_type = 'export_pdf';\n  \n  // Try to extract report ID or title\n  const reportMatch = message.match(/report\\s+(\\w+)|\"([^\"]+)\"/i);\n  if (reportMatch) {\n    request.command_params.report_identifier = reportMatch[1] || reportMatch[2];\n  }\n}\n\nelse if (message.includes('list reports') || message.includes('show reports') || message.includes('my reports')) {\n  request.is_command = true;\n  request.command_type = 'list_reports';\n  \n  // Extract filters\n  if (message.includes('recent')) {\n    request.command_params.time_filter = 'recent';\n  }\n  if (message.includes('category')) {\n    const categoryMatch = message.match(/category\\s+(\\w+)/i);\n    if (categoryMatch) {\n      request.command_params.category = categoryMatch[1];\n    }\n  }\n}\n\nreturn request;"
      },
      "id": "process-message",
      "name": "Process Chat Message",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 300]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- First ensure conversation exists\nINSERT INTO research_assistant.chat_conversations (id, user_id, organization, is_active)\nVALUES ('{{ $json.conversation_id }}', '{{ $json.user_id }}', '{{ $json.organization }}', true)\nON CONFLICT (id) DO UPDATE SET \n  last_message_at = NOW(),\n  message_count = chat_conversations.message_count + 1;\n\n-- Insert the user message\nINSERT INTO research_assistant.chat_messages \n(id, conversation_id, role, content, created_at)\nVALUES \n('{{ $json.message_id }}', '{{ $json.conversation_id }}', 'user', '{{ $json.message }}', NOW())\nRETURNING id;",
        "additionalFields": {}
      },
      "id": "save-user-message",
      "name": "Save User Message",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [680, 300],
      "credentials": {
        "postgres": {
          "id": "postgres-research",
          "name": "Research Assistant DB"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "is_command",
              "leftValue": "={{ $('Process Chat Message').item.json.is_command }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equal"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "check-command",
      "name": "Check if Command",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [900, 300]
    },
    {
      "parameters": {
        "url": "http://localhost:5678/webhook/embed",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "text",
              "value": "={{ $('Process Chat Message').item.json.message }}"
            },
            {
              "name": "model",
              "value": "nomic-embed-text"
            },
            {
              "name": "store_in_qdrant",
              "value": "false"
            }
          ]
        },
        "options": {
          "timeout": 30000
        }
      },
      "id": "generate-query-embedding",
      "name": "Generate Query Embedding (Shared)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1120, 400]
    },
    {
      "parameters": {
        "url": "http://localhost:6333/collections/research-documents/points/search",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "vector",
              "value": "={{ $json.embedding }}"
            },
            {
              "name": "limit",
              "value": "5"
            },
            {
              "name": "score_threshold",
              "value": "0.7"
            },
            {
              "name": "with_payload",
              "value": "true"
            }
          ]
        },
        "options": {
          "timeout": 15000
        }
      },
      "id": "search-relevant-reports",
      "name": "Search Relevant Reports",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1340, 400]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Get conversation history for context\nconst conversationId = $('Process Chat Message').item.json.conversation_id;\nconst userMessage = $('Process Chat Message').item.json.message;\nconst searchResults = $input.item.json.result || [];\n\n// Build context from relevant reports\nlet contextSources = [];\nif (searchResults.length > 0) {\n  contextSources = searchResults.map((result, idx) => {\n    const payload = result.payload || {};\n    return {\n      index: idx + 1,\n      title: payload.title || 'Untitled Report',\n      summary: payload.summary || '',\n      confidence: payload.confidence_score || 0,\n      relevance_score: result.score || 0,\n      created_at: payload.created_at || '',\n      report_id: payload.report_id || ''\n    };\n  }).filter(source => source.relevance_score >= 0.7);\n}\n\n// Build system prompt\nlet systemPrompt = `You are a professional research assistant. You help users discuss and analyze research reports, and can trigger new research when requested.\n\n**Your capabilities:**\n- Answer questions about existing research reports\n- Provide summaries and insights from previous research\n- Generate new research reports when requested\n- Schedule recurring reports\n- Export reports to PDF\n\n**Guidelines:**\n- Be concise but thorough\n- Always cite specific reports when referencing information\n- If you don't have relevant information, say so clearly\n- For new research requests, confirm the topic and depth before proceeding\n- Use bullet points for lists and key findings\n- Maintain a professional but friendly tone`;\n\n// Add context if we have relevant reports\nif (contextSources.length > 0) {\n  systemPrompt += `\\n\\n**Relevant Research Context:**\\n`;\n  contextSources.forEach(source => {\n    systemPrompt += `[${source.index}] ${source.title} (Relevance: ${(source.relevance_score * 100).toFixed(0)}%, Confidence: ${(source.confidence * 100).toFixed(0)}%)\\n${source.summary}\\n\\n`;\n  });\n  systemPrompt += `\\n**Instructions:** Use this context to answer the user's question. Reference reports using [1], [2], etc. when citing specific information.`;\n} else {\n  systemPrompt += `\\n\\n**Note:** No directly relevant research reports found for this query. Provide general guidance and offer to generate new research if appropriate.`;\n}\n\n// Build the full prompt\nconst fullPrompt = `${systemPrompt}\\n\\n**User Question:** ${userMessage}\\n\\n**Response:**`;\n\nreturn {\n  conversation_id: conversationId,\n  user_message: userMessage,\n  context_sources: contextSources,\n  system_prompt: systemPrompt,\n  full_prompt: fullPrompt,\n  has_context: contextSources.length > 0\n};"
      },
      "id": "build-context",
      "name": "Build Context for Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1560, 400]
    },
    {
      "parameters": {
        "url": "http://localhost:5678/webhook/ollama",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "prompt",
              "value": "={{ $json.full_prompt }}"
            },
            {
              "name": "model",
              "value": "qwen2.5:32b"
            },
            {
              "name": "type",
              "value": "reasoning"
            },
            {
              "name": "quiet",
              "value": "true"
            },
            {
              "name": "timeout_seconds",
              "value": "60"
            }
          ]
        },
        "options": {
          "timeout": 60000
        }
      },
      "id": "generate-response",
      "name": "Generate AI Response (Shared Ollama)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1780, 400]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Process AI response and prepare for storage\nconst contextData = $('Build Context for Response').item.json;\nconst aiResponse = $input.item.json.response || 'I apologize, but I was unable to generate a response. Please try again.';\nconst processingTime = Date.now() - $('Process Chat Message').item.json.processing_start;\n\n// Calculate confidence score based on context availability and response quality\nlet confidenceScore = 0.5; // Base confidence\nif (contextData.has_context) {\n  confidenceScore += 0.3; // Higher confidence with relevant context\n}\nif (aiResponse.length > 100) {\n  confidenceScore += 0.1; // Higher confidence for substantial responses\n}\nif (aiResponse.includes('[1]') || aiResponse.includes('[2]')) {\n  confidenceScore += 0.1; // Higher confidence when citing sources\n}\n\nconfidenceScore = Math.min(0.95, confidenceScore);\n\nreturn {\n  conversation_id: contextData.conversation_id,\n  response_content: aiResponse,\n  context_sources: contextData.context_sources,\n  confidence_score: parseFloat(confidenceScore.toFixed(2)),\n  processing_time_ms: processingTime,\n  has_citations: aiResponse.includes('[1]') || aiResponse.includes('[2]'),\n  response_length: aiResponse.length\n};"
      },
      "id": "process-response",
      "name": "Process AI Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2000, 400]
    },
    {
      "parameters": {
        "operation": "insert",
        "schema": "research_assistant",
        "table": "chat_messages",
        "columns": "conversation_id, role, content, context_sources, confidence_score, processing_time_ms",
        "additionalFields": {
          "mode": "independently"
        }
      },
      "id": "save-response",
      "name": "Save AI Response",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [2220, 400],
      "credentials": {
        "postgres": {
          "id": "postgres-research",
          "name": "Research Assistant DB"
        }
      }
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "{\n  \"success\": true,\n  \"response\": \"{{ $('Process AI Response').item.json.response_content }}\",\n  \"conversation_id\": \"{{ $('Process AI Response').item.json.conversation_id }}\",\n  \"has_context\": {{ $('Process AI Response').item.json.has_citations }},\n  \"confidence_score\": {{ $('Process AI Response').item.json.confidence_score }},\n  \"processing_time_ms\": {{ $('Process AI Response').item.json.processing_time_ms }},\n  \"sources_used\": {{ $('Process AI Response').item.json.context_sources.length }},\n  \"timestamp\": \"{{ new Date().toISOString() }}\"\n}"
      },
      "id": "chat-response",
      "name": "Return Chat Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [2440, 400]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "generate_report",
              "leftValue": "={{ $('Process Chat Message').item.json.command_type }}",
              "rightValue": "generate_report",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "check-generate-report",
      "name": "Check Generate Report Command",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [1120, 200]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Prepare research request from command\nconst messageData = $('Process Chat Message').item.json;\nconst params = messageData.command_params;\n\n// Validate required parameters\nif (!params.topic) {\n  return {\n    error: 'Please specify a topic for the research report. For example: \"Generate a report on artificial intelligence trends\"',\n    needs_clarification: true\n  };\n}\n\n// Build research request\nconst researchRequest = {\n  id: `chat-${messageData.message_id}-${Date.now()}`,\n  topic: params.topic,\n  depth: params.depth || 'standard',\n  target_length: params.target_length || 5,\n  language: 'en',\n  requested_by: messageData.user_id,\n  organization: messageData.organization,\n  custom_prompts: {\n    tone: 'professional',\n    source_emphasis: 'academic research prioritized'\n  }\n};\n\nreturn {\n  research_request: researchRequest,\n  conversation_id: messageData.conversation_id,\n  user_id: messageData.user_id,\n  confirmation_message: `I'll generate a ${params.depth} research report on \"${params.topic}\" (approximately ${params.target_length} pages). This may take 5-15 minutes depending on the depth and complexity.`\n};"
      },
      "id": "prepare-research-request",
      "name": "Prepare Research Request",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1340, 140]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "no_error",
              "leftValue": "={{ $json.error }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "notExists"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "validate-request",
      "name": "Validate Research Request",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [1560, 140]
    },
    {
      "parameters": {
        "url": "http://localhost:5678/webhook/research-request",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "body",
              "value": "={{ JSON.stringify($json.research_request) }}"
            }
          ]
        },
        "options": {
          "timeout": 5000,
          "retry": {
            "enabled": false
          }
        }
      },
      "id": "trigger-research-async",
      "name": "Trigger Research (Async)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1780, 100]
    },
    {
      "parameters": {
        "operation": "insert",
        "schema": "research_assistant",
        "table": "chat_messages",
        "columns": "conversation_id, role, content, triggered_report_id, triggered_action",
        "additionalFields": {
          "mode": "independently"
        }
      },
      "id": "save-command-response",
      "name": "Save Command Response",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [2000, 100],
      "credentials": {
        "postgres": {
          "id": "postgres-research",
          "name": "Research Assistant DB"
        }
      }
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "{\n  \"success\": true,\n  \"response\": \"{{ $('Prepare Research Request').item.json.confirmation_message }}\",\n  \"conversation_id\": \"{{ $('Prepare Research Request').item.json.conversation_id }}\",\n  \"action\": \"research_triggered\",\n  \"report_id\": \"{{ $('Prepare Research Request').item.json.research_request.id }}\",\n  \"estimated_completion\": \"{{ new Date(Date.now() + 15 * 60 * 1000).toISOString() }}\",\n  \"timestamp\": \"{{ new Date().toISOString() }}\"\n}"
      },
      "id": "command-response",
      "name": "Return Command Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [2220, 100]
    },
    {
      "parameters": {
        "operation": "insert",
        "schema": "research_assistant",
        "table": "chat_messages",
        "columns": "conversation_id, role, content",
        "additionalFields": {
          "mode": "independently"
        }
      },
      "id": "save-error-response",
      "name": "Save Error Response",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [1780, 180],
      "credentials": {
        "postgres": {
          "id": "postgres-research",
          "name": "Research Assistant DB"
        }
      }
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "{\n  \"success\": true,\n  \"response\": \"{{ $('Prepare Research Request').item.json.error }}\",\n  \"conversation_id\": \"{{ $('Prepare Research Request').item.json.conversation_id }}\",\n  \"needs_clarification\": true,\n  \"timestamp\": \"{{ new Date().toISOString() }}\"\n}"
      },
      "id": "error-response",
      "name": "Return Error Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [2000, 180]
    }
  ],
  "pinData": {},
  "connections": {
    "Chat Message Webhook": {
      "main": [
        [
          {
            "node": "Process Chat Message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process Chat Message": {
      "main": [
        [
          {
            "node": "Save User Message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save User Message": {
      "main": [
        [
          {
            "node": "Check if Command",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check if Command": {
      "main": [
        [
          {
            "node": "Check Generate Report Command",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Generate Query Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Query Embedding": {
      "main": [
        [
          {
            "node": "Search Relevant Reports",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Search Relevant Reports": {
      "main": [
        [
          {
            "node": "Build Context for Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Context for Response": {
      "main": [
        [
          {
            "node": "Generate AI Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate AI Response": {
      "main": [
        [
          {
            "node": "Process AI Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process AI Response": {
      "main": [
        [
          {
            "node": "Save AI Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save AI Response": {
      "main": [
        [
          {
            "node": "Return Chat Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Generate Report Command": {
      "main": [
        [
          {
            "node": "Prepare Research Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Research Request": {
      "main": [
        [
          {
            "node": "Validate Research Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Research Request": {
      "main": [
        [
          {
            "node": "Trigger Research (Async)",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Save Error Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Trigger Research (Async)": {
      "main": [
        [
          {
            "node": "Save Command Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Command Response": {
      "main": [
        [
          {
            "node": "Return Command Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Error Response": {
      "main": [
        [
          {
            "node": "Return Error Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1",
    "saveManualExecutions": true,
    "callerPolicy": "workflowsFromSameOwner"
  },
  "versionId": "1",
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "id": "chat-rag-workflow",
  "tags": []
}
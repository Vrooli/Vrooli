# SaaS Landing Manager Scenario Test Configuration
# This file defines comprehensive validation criteria for the saas-landing-manager scenario

version: 1.0
scenario: saas-landing-manager

# Structure validation - files and directories that MUST exist
structure:
  required_files:
    - .vrooli/service.json
    - PRD.md
    - README.md
    - api/main.go
    - api/go.mod
    - cli/main.go
    - cli/go.mod
    - cli/install.sh
    - ui/package.json
    - ui/server.js
    - ui/index.html
    - ui/styles.css
    - ui/app.js
    - initialization/storage/postgres/schema.sql
    - initialization/storage/postgres/seed.sql
    - scenario-test.yaml
    
  required_dirs:
    - api
    - cli
    - ui
    - initialization
    - initialization/storage
    - initialization/storage/postgres
    - templates
    - templates/base
    - templates/industry
    - templates/components
    - data
    - test

# Resource validation
resources:
  required: [postgres]
  optional: [claude-code, ollama, browserless]
  health_timeout: 60

# Service validation tests
tests:
  # Health checks
  - name: "API server health check"
    type: http
    service: api
    endpoint: /health
    method: GET
    expect:
      status: 200
      body:
        status: "healthy"
        service: "saas-landing-manager"

  - name: "UI server health check"
    type: http
    service: ui
    endpoint: /health
    method: GET
    expect:
      status: 200
      body:
        status: "healthy"
        service: "saas-landing-manager-ui"

  - name: "UI dashboard loads"
    type: http
    service: ui
    endpoint: /
    method: GET
    expect:
      status: 200
      content_contains: ["SaaS Landing Manager", "Dashboard"]

  # Database integration tests
  - name: "Database schema is initialized"
    type: sql
    service: postgres
    query: "SELECT COUNT(*) as count FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('saas_scenarios', 'landing_pages', 'templates', 'ab_test_results')"
    expect:
      rows:
        - count: 4

  - name: "Seed templates are loaded"
    type: sql
    service: postgres
    query: "SELECT COUNT(*) as count FROM templates WHERE category = 'base'"
    expect:
      rows:
        - count: ">= 3"

  # API endpoint tests
  - name: "SaaS scenario scanning endpoint"
    type: http
    service: api
    endpoint: /api/v1/scenarios/scan
    method: POST
    body:
      force_rescan: true
      scenario_filter: ""
    expect:
      status: 200
      body:
        total_scenarios: ">= 0"
        saas_scenarios: ">= 0"
        newly_detected: ">= 0"

  - name: "Templates listing endpoint"
    type: http
    service: api
    endpoint: /api/v1/templates
    method: GET
    expect:
      status: 200
      body:
        templates: "array"

  - name: "Analytics dashboard endpoint"
    type: http
    service: api
    endpoint: /api/v1/analytics/dashboard
    method: GET
    expect:
      status: 200
      body:
        total_pages: ">= 0"
        active_ab_tests: ">= 0"

  - name: "Landing page generation endpoint structure"
    type: http
    service: api
    endpoint: /api/v1/landing-pages/generate
    method: POST
    body:
      scenario_id: "test-scenario"
      enable_ab_testing: false
    expect:
      status: [200, 400, 404]  # Accept 400/404 for test scenario, but endpoint should respond

  # CLI functionality tests
  - name: "CLI binary is executable"
    type: exec
    command: ./cli/saas-landing-manager version --json
    expect:
      exit_code: 0
      output_contains: ["version", "saas-landing-manager"]

  - name: "CLI status command works"
    type: exec
    command: ./cli/saas-landing-manager status --json
    expect:
      exit_code: [0, 1]  # Accept failure if API not running
      output_contains: ["status", "service"]

  - name: "CLI help command works"
    type: exec
    command: ./cli/saas-landing-manager help
    expect:
      exit_code: 0
      output_contains: ["SaaS Landing Manager CLI", "COMMANDS", "scan", "generate", "deploy"]

  - name: "CLI scan dry run works"
    type: exec
    command: ./cli/saas-landing-manager scan --dry-run --json
    expect:
      exit_code: [0, 1]  # Accept failure if API not running
      
  - name: "CLI template list works"
    type: exec
    command: ./cli/saas-landing-manager template list
    expect:
      exit_code: [0, 1]  # Accept failure if API not running

  # Build and compilation tests
  - name: "API Go build succeeds"
    type: exec
    command: cd api && go build -o test-build . && rm -f test-build
    expect:
      exit_code: 0

  - name: "CLI Go build succeeds"
    type: exec
    command: cd cli && go build -o test-build . && rm -f test-build
    expect:
      exit_code: 0

  - name: "UI dependencies install"
    type: exec
    command: cd ui && npm install --silent
    expect:
      exit_code: 0

  # File permissions and structure tests
  - name: "CLI install script is executable"
    type: exec
    command: test -x ./cli/install.sh
    expect:
      exit_code: 0

  - name: "Template directories exist and are readable"
    type: exec
    command: test -r ./templates/base && test -r ./templates/industry && test -r ./templates/components
    expect:
      exit_code: 0

  # Configuration validation
  - name: "Service configuration is valid JSON"
    type: exec
    command: python3 -m json.tool .vrooli/service.json > /dev/null
    expect:
      exit_code: 0

  - name: "Package.json is valid JSON"
    type: exec
    command: python3 -m json.tool ui/package.json > /dev/null
    expect:
      exit_code: 0

  # Advanced integration tests (optional - run when resources available)
  - name: "SaaS scenario detection accuracy test"
    type: integration
    condition:
      resource_available: [postgres]
    setup:
      - "Create test scenario structure"
    test:
      - endpoint: /api/v1/scenarios/scan
        method: POST
        body: 
          force_rescan: true
          scenario_filter: "test"
    expect:
      - "Scenarios are detected with confidence scores"
      - "Database is populated with results"
    cleanup:
      - "Remove test scenario structure"

  - name: "Landing page generation workflow test"
    type: integration
    condition:
      resource_available: [postgres]
    test:
      - step: "Generate landing page"
        endpoint: /api/v1/landing-pages/generate
        method: POST
        body:
          scenario_id: "test-scenario"
          template_id: "b2b-tool-template"
          enable_ab_testing: true
      - step: "Verify database records"
        sql: "SELECT * FROM landing_pages WHERE scenario_id = 'test-scenario'"
    expect:
      - "Landing page record created"
      - "A/B test variants created if enabled"
      - "Template usage count incremented"

# Performance benchmarks
performance:
  - name: "API response time"
    endpoint: /api/v1/templates
    target: "< 1000ms"
    samples: 10

  - name: "UI load time"
    endpoint: /
    target: "< 2000ms"
    samples: 5

  - name: "Scenario scan performance"
    endpoint: /api/v1/scenarios/scan
    target: "< 30000ms"  # 30 seconds for full scan
    samples: 3

# Security tests
security:
  - name: "No hardcoded secrets in config"
    type: exec
    command: grep -r "password\|secret\|key" .vrooli/service.json || true
    expect:
      output_not_contains: ["password", "secret", "api_key"]

  - name: "SQL injection prevention"
    type: security
    endpoint: /api/v1/scenarios/scan
    method: POST
    body:
      scenario_filter: "'; DROP TABLE saas_scenarios; --"
    expect:
      - "Request handled safely"
      - "Database tables remain intact"

# Documentation tests
documentation:
  - name: "README exists and has required sections"
    type: exec
    command: test -f README.md
    expect:
      exit_code: 0

  - name: "PRD follows template structure"
    type: exec
    command: grep -q "## ðŸŽ¯ Capability Definition" PRD.md && grep -q "## ðŸ“Š Success Metrics" PRD.md
    expect:
      exit_code: 0

  - name: "API documentation exists"
    type: exec  
    command: grep -q "API" README.md || test -f docs/api.md
    expect:
      exit_code: 0

# Cleanup after tests
cleanup:
  - "Stop all running services"
  - "Clean up temporary test files"
  - "Reset database to clean state"

# Test execution configuration
config:
  timeout: 300  # 5 minutes total timeout
  parallel: true  # Run tests in parallel where possible
  retry_count: 2  # Retry failed tests up to 2 times
  verbose: true   # Show detailed output
  
# Test environments
environments:
  - name: "local"
    description: "Local development environment"
    required_resources: [postgres]
    
  - name: "ci"
    description: "Continuous integration environment"
    required_resources: [postgres]
    skip_tests: ["integration"]  # Skip heavy integration tests in CI
    
  - name: "staging" 
    description: "Staging environment with all resources"
    required_resources: [postgres, claude-code, ollama, browserless]
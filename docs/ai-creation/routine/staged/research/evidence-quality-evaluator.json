{
  "id": "7829564732190848243",
  "publicId": "evidence-quality-evaluator-v1",
  "resourceType": "Routine",
  "isPrivate": false,
  "permissions": "{}",
  "isInternal": false,
  "tags": [
    {
      "id": "7829564732190847032",
      "publicId": "research-tag",
      "resourceType": "Tag",
      "language": "en-US",
      "tag": "research"
    },
    {
      "id": "7829564732190847099",
      "publicId": "analysis-tag",
      "resourceType": "Tag",
      "language": "en-US",
      "tag": "analysis"
    }
  ],
  "versions": [
    {
      "id": "7829564732190848244",
      "publicId": "evidence-quality-evaluator-v1-0",
      "versionLabel": "1.0.0",
      "versionNotes": "Initial version - Evaluates evidence quality and credibility for fact-checking",
      "isComplete": true,
      "isPrivate": false,
      "versionIndex": 0,
      "isAutomatable": true,
      "resourceSubType": "RoutineGenerate",
      "config": {
        "__version": "1.0",
        "callDataGenerate": {
          "__version": "1.0",
          "schema": {
            "botStyle": "Analytical",
            "maxTokens": 700,
            "model": null,
            "prompt": "Evaluate the quality and credibility of evidence for fact-checking:\n\nEvidence Sources: {{input.evidenceSources}}\nSource Credibility Notes: {{input.sourceCredibilityNotes}}\nOriginal Claims: {{input.originalClaims}}\nEvaluation Standards: {{input.evaluationStandards}}\n\nPerform comprehensive evidence evaluation:\n\n1. **Source Credibility Assessment**:\n   - Author expertise and credentials\n   - Publication reputation\n   - Editorial oversight\n   - Peer review status\n   - Institutional affiliation\n\n2. **Content Quality Analysis**:\n   - Accuracy of information\n   - Completeness of coverage\n   - Currency and timeliness\n   - Methodological rigor\n   - Data quality and sources\n\n3. **Bias and Reliability Evaluation**:\n   - Political or commercial bias\n   - Conflicts of interest\n   - Balanced presentation\n   - Transparency of methods\n   - Correction policies\n\n4. **Evidence Strength Classification**:\n   - Primary vs secondary sources\n   - Direct vs circumstantial evidence\n   - Corroboration level\n   - Statistical significance\n   - Expert consensus\n\n5. **Relevance and Applicability**:\n   - Direct relevance to claims\n   - Contextual appropriateness\n   - Temporal relevance\n   - Geographic applicability\n   - Scope alignment\n\n6. **Cross-Verification Analysis**:\n   - Independent confirmation\n   - Contradictory evidence\n   - Consensus assessment\n   - Outlier identification\n   - Reliability patterns\n\n7. **Quality Scoring System**:\n   - Overall credibility score (1-10)\n   - Evidence strength rating\n   - Reliability confidence level\n   - Bias risk assessment\n   - Verification status\n\nReturn as structured JSON with keys: credibilityScores (object), qualityAnalysis (object), biasAssessment (object), evidenceStrength (array), relevanceScores (object), crossVerification (object), overallRating (object).",
            "respondingBot": null
          }
        },
        "formInput": {
          "__version": "1.0",
          "schema": {
            "containers": [],
            "elements": [
              {
                "fieldName": "evidenceSources",
                "id": "evidence_input",
                "label": "Evidence Sources",
                "type": "Text",
                "isRequired": true,
                "props": {
                  "placeholder": "Sources and evidence found during research...",
                  "multiline": true,
                  "rows": 4
                }
              },
              {
                "fieldName": "sourceCredibilityNotes",
                "id": "credibility_input",
                "label": "Source Credibility Notes",
                "type": "Text",
                "isRequired": true,
                "props": {
                  "placeholder": "Initial credibility assessments from research...",
                  "multiline": true,
                  "rows": 3
                }
              },
              {
                "fieldName": "originalClaims",
                "id": "claims_input",
                "label": "Original Claims",
                "type": "Text",
                "isRequired": true,
                "props": {
                  "placeholder": "The original claims being fact-checked...",
                  "multiline": true,
                  "rows": 2
                }
              },
              {
                "fieldName": "evaluationStandards",
                "id": "standards_input",
                "label": "Evaluation Standards",
                "type": "Selector",
                "props": {
                  "options": ["Academic Research", "Journalism", "Legal Evidence", "Scientific Peer Review", "General Public", "High Scrutiny"]
                }
              }
            ]
          }
        },
        "formOutput": {
          "__version": "1.0",
          "schema": {
            "containers": [],
            "elements": [
              {
                "fieldName": "qualityAssessment",
                "id": "quality_output",
                "label": "Evidence Quality Assessment",
                "type": "Text"
              },
              {
                "fieldName": "credibilityRanking",
                "id": "ranking_output",
                "label": "Source Credibility Ranking",
                "type": "Text"
              }
            ]
          }
        },
        "executionStrategy": "reasoning"
      },
      "labels": [],
      "translations": [
        {
          "id": "7829564732190848245",
          "language": "en-US",
          "description": "Evaluates evidence quality and source credibility with systematic scoring and bias assessment",
          "instructions": "Provide evidence sources, credibility notes, and original claims. The system will evaluate quality, assess bias, and rank sources by credibility.",
          "name": "Evidence Quality Evaluator"
        }
      ]
    }
  ]
}
# Knowledge Observatory Canonical Knowledge Management Plan

**Goal**: Make `scenarios/knowledge-observatory/api` the canonical control-plane for “knowledge generation and management” across Vrooli: ingestion → chunking → embedding (Ollama) → persistence (Qdrant vectors + Postgres metadata) → retrieval (search) → derived health/metrics/graph.

**Status**: In Progress
**Created**: 2025-12-17
**Target Scenario**: `scenarios/knowledge-observatory`
**Key Constraint**: Keep using existing resources (Qdrant, Postgres, Ollama, etc.); centralize logic in KO rather than replacing resources.

---

## Context (Decisions + Non-Goals)

### Decisions from stakeholders

- Other scenarios will integrate via **HTTP** or via the **Knowledge Observatory CLI** (thin client calling HTTP).
- KO remains resource-backed: **Qdrant** stays the vector DB; **Ollama** stays the embedding provider; **Postgres** stays the metadata store.
- KO becomes the **only authoritative writer** (control-plane) for knowledge that scenarios want Vrooli to “remember” and manage.

### Non-goals (for this plan)

- Replacing Qdrant with an embedded vector store.
- Adding new third-party dependencies without explicit approval.
- Tight coupling other scenarios to KO internals (no required Go imports; HTTP/CLI first).

---

## Executive Summary

Today, “knowledge generation” is effectively distributed: scenarios can create embeddings and write vectors directly to Qdrant, producing inconsistent payload schemas, id generation rules, provenance, dedupe behavior, and quality/graph derivations.

This plan centralizes the **write path** into Knowledge Observatory’s Go API, while keeping Qdrant as the storage backend. KO becomes a stable platform capability:

- **Uniform payload schema** (provenance, namespace/visibility, timestamps, hashes).
- **Idempotent ingestion** (content hash + external IDs).
- **Clear operational semantics** (sync small ingests, async bulk ingests).
- **Auditable metadata** in Postgres (ingest ledger, search history, derived metrics).
- **Strong seams** to test (vector store/embedding/metadata ports).

---

## Architecture Overview (Screaming Boundaries)

### Responsibility boundaries

| Component | Owns | Does not own |
|---|---|---|
| `knowledge-observatory/api` | Knowledge ingestion rules, chunking, embedding orchestration, payload schema, idempotency, provenance, Qdrant writes, derived metrics/graph materialization | Raw vector similarity implementation details (Qdrant owns), per-scenario private embedding logic |
| Qdrant resource | Vector storage + ANN search | Knowledge semantics, schema governance, dedupe rules |
| Ollama resource | Embedding generation | Collection management, provenance, dedupe |
| Postgres resource | Metadata, ingest ledger, metrics, relationships | Vector similarity, embedding inference |
| KO CLI | UX + convenience for calling KO API | Embedding/vector storage logic |

### Layering in KO API (recommended)

1. **HTTP Handlers**: request parsing + validation + mapping to service calls (no Qdrant/Ollama logic).
2. **Application Services**:
   - `IngestService`: canonical write path.
   - `SearchService`: canonical read path.
   - `MetricsService`, `GraphService`: derived views/materialization.
3. **Ports (interfaces)**:
   - `VectorStore` (Qdrant adapter)
   - `Embedder` (Ollama adapter)
   - `MetadataStore` (Postgres adapter)
4. **Adapters**: Qdrant HTTP client, Ollama HTTP client, Postgres queries.

This ensures:
- stable seams for unit tests (fakes for ports),
- low-risk refactors,
- clear ownership boundaries (screaming architecture).

---

## Canonical Data Model

### Knowledge primitives

**`KnowledgeDocument`** (semantic unit)
- `namespace` (required; typically scenario id)
- `external_id` (optional; stable id from source system)
- `title` (optional)
- `content` (required; raw text)
- `source` (optional; URL/file/scenario)
- `tags` (optional)
- `created_at` / `observed_at` (optional; for freshness)

**`KnowledgeChunk`** (storage/search unit)
- `record_id` (canonical KO id; stable)
- `document_id` (links chunk to document)
- `chunk_index` (int; ordering)
- `chunk_text` (stored for display)
- `content_hash` (sha256 of normalized chunk content + key fields)
- `embedding` (generated by KO, stored in Qdrant)
- `payload` (schema-governed; see below)

### Payload schema in Qdrant (KO-governed)

All vectors written by KO follow a stable schema to support filtering, provenance, and derivations:

- `schema_version`: `"ko.knowledge.v1"`
- `namespace`: scenario id (string)
- `visibility`: `"private" | "shared" | "global"` (default: `"shared"`)
- `document_id`: string
- `record_id`: string
- `chunk_index`: number
- `content`: string (chunk text)
- `content_hash`: string (sha256)
- `source`: string (URL/path/scenario ref, optional)
- `source_type`: string (`"scenario"|"doc"|"web"|"manual"|...`, optional)
- `ingested_at`: RFC3339 string
- `metadata`: object (free-form, namespaced under this key)

Avoid storing arbitrary metadata at the top-level payload keys to prevent collisions across producers.

---

## Tenancy / Namespacing (choice)

Use **payload-level tenancy** with a required `namespace` field, and (initially) a small number of physical Qdrant collections:

- Default collection: `knowledge_chunks_v1`
- Optional: allow `collection` override for experiments/migrations, but KO should default to the canonical collection.

Benefits:
- avoids “collection explosion” (ops simplicity),
- supports cross-scenario search (filter by multiple namespaces),
- keeps schema governance centralized.

---

## Sync vs Async Ingestion (choice)

Default mode is **synchronous** for small ingests:
- call returns only after embedding + Qdrant upsert succeeds,
- writes ingest metadata to Postgres for audit.

For large ingests, KO supports **async jobs** (Postgres-backed queue; no new deps):
- `POST /api/v1/ingest/jobs` returns `job_id`,
- worker goroutines process chunks,
- `GET /api/v1/ingest/jobs/{id}` for status/errors,
- idempotency via content hash + external ids.

---

## API Surface (HTTP)

### Read path (existing + extensions)

- `POST /api/v1/knowledge/search`
  - Add filters: `namespace(s)`, `visibility`, `tags`, time windows.
- `GET /api/v1/knowledge/health`
  - Derive collection/namespace health from Qdrant stats + Postgres ledger.

### Write path (new)

Start with chunk/record ingestion (simple), then add document ingestion:

- `POST /api/v1/knowledge/records/upsert`
  - body: `{ namespace, content, metadata?, visibility?, source?, source_type?, collection? }`
  - server: chunk (initially 1 chunk) → embed → ensure collection exists → upsert point(s) → write metadata.
- `DELETE /api/v1/knowledge/records/{record_id}`
  - deletes/tombstones and deletes Qdrant point.

Next:
- `POST /api/v1/knowledge/documents/ingest` (chunking + batching)
- `POST /api/v1/ingest/jobs` (async)

---

## CLI Surface (thin client)

Expand `scenarios/knowledge-observatory/cli/knowledge-observatory` to support:

- `ingest` (file/url/stdin; posts to KO API)
- `search` (posts to KO API)
- `metrics` / `health` (GET)
- `graph` (GET/POST)

CLI must not embed vectors nor call Qdrant directly; it calls KO’s HTTP API.

---

## Testing Strategy (audit-grade seams)

### Unit tests (no resources)

- Request validation and normalization (ingest/search).
- Content hashing + idempotency key derivation.
- Payload schema mapping (no collisions; schema_version always set).
- `IngestService` orchestration using fakes:
  - Fake embedder returns deterministic vectors
  - Fake vector store records upserts
  - Fake metadata store records writes

### Adapter tests

- Qdrant adapter: request formation + error mapping using `httptest` server.
- Ollama adapter: embedding request/response handling using `httptest` server.

### Integration tests (resources; scenario test phase)

- With Qdrant + Postgres running:
  - Ingest → search returns that record
  - Namespace filter works
  - Health endpoint reflects expected counts

---

## Migration / Adoption

1. Implement KO write APIs and use them from KO’s own CLI.
2. Update a first consumer scenario to use KO for writes (feature-flag if needed).
3. Operational hardening: rate limits, auth, quotas, job queue, replay, observability.
4. Long-term: restrict Qdrant write credentials to KO; other scenarios use KO only.

---

## Implementation Phases (checklist)

### Phase 0 — Establish seams (low risk)

- [ ] Introduce application services and ports (interfaces) in KO API.
- [ ] Keep existing search endpoint behavior intact while refactoring internals.

### Phase 1 — Canonical write path (sync)

- [ ] Add `POST /api/v1/knowledge/records/upsert`.
- [ ] Implement Ollama embedding orchestration with consistent errors/timeouts.
- [ ] Implement Qdrant upsert + ensure-collection logic.
- [ ] Persist ingest metadata in Postgres (`knowledge_metadata`, and/or new ledger tables).

### Phase 2 — CLI support

- [ ] Add `knowledge-observatory ingest ...`
- [ ] Add `knowledge-observatory search ...` (stopgap until UI uses it)

### Phase 3 — Async ingestion + chunking

- [ ] Add job tables and worker.
- [ ] Add `documents/ingest` with chunking strategy.

### Phase 4 — Derived views

- [ ] Materialize graph edges and quality metrics from KO-governed payload schema.

---

## File Manifest (expected touch points)

**KO API**
- `scenarios/knowledge-observatory/api/server.go` (routes + dependency wiring)
- `scenarios/knowledge-observatory/api/search.go` (refactor to service/ports)
- `scenarios/knowledge-observatory/api/metrics.go` (derive from KO schema)
- `scenarios/knowledge-observatory/api/ingest.go` (new handler + validation)
- `scenarios/knowledge-observatory/api/internal/...` (new packages for ports/services/adapters)

**DB**
- `scenarios/knowledge-observatory/initialization/postgres/schema.sql` (ledger tables if needed)

**CLI**
- `scenarios/knowledge-observatory/cli/knowledge-observatory` (new commands)

**Docs**
- `scenarios/knowledge-observatory/README.md` (correct CLI/API examples)
- `scenarios/knowledge-observatory/docs/PROGRESS.md` (work log)

---

## Reference Links

- Scenario: `scenarios/knowledge-observatory`
- Service definition: `scenarios/knowledge-observatory/.vrooli/service.json`
- Existing search endpoint: `scenarios/knowledge-observatory/api/search.go`
- Existing health endpoint: `scenarios/knowledge-observatory/api/metrics.go`


# Auto/ System Technical Architecture

## ðŸ—ï¸ System Overview

The auto/ system implements a modular, event-driven architecture for orchestrating Claude Code in continuous improvement loops. It consists of a generic loop core, task-specific modules, and supporting infrastructure for process management, logging, and metrics.

## ðŸ“ Component Architecture

```
auto/
â”œâ”€â”€ Entry Points (Shell Scripts)
â”‚   â”œâ”€â”€ task-manager.sh          # Central dispatcher
â”‚   â”œâ”€â”€ manage-resource-loop.sh  # Resource task convenience wrapper
â”‚   â””â”€â”€ manage-scenario-loop.sh  # Scenario task convenience wrapper
â”‚
â”œâ”€â”€ Core Libraries (lib/)
â”‚   â”œâ”€â”€ loop.sh                  # Main orchestration loop
â”‚   â”œâ”€â”€ core.sh                  # Core utilities and constants
â”‚   â”œâ”€â”€ process.sh               # Process management
â”‚   â”œâ”€â”€ workers.sh               # Worker lifecycle management
â”‚   â”œâ”€â”€ events.sh                # Event logging and tracking
â”‚   â”œâ”€â”€ dispatch.sh              # Command routing
â”‚   â””â”€â”€ error-handler.sh         # Error handling and recovery
â”‚
â”œâ”€â”€ Task Modules (tasks/)
â”‚   â””â”€â”€ [task-name]/
â”‚       â”œâ”€â”€ task.sh              # Task-specific hooks
â”‚       â””â”€â”€ prompts/             # Task prompts
â”‚           â””â”€â”€ *.md             # Prompt templates
â”‚
â”œâ”€â”€ Tools (tools/)
â”‚   â””â”€â”€ selection/               # Intelligent selection algorithms
â”‚       â”œâ”€â”€ resource-candidates.sh
â”‚       â””â”€â”€ scenario-recommend.sh
â”‚
â””â”€â”€ Runtime Data (data/)
    â””â”€â”€ [task-name]/
        â”œâ”€â”€ loop.pid             # Process ID
        â”œâ”€â”€ loop.log             # Main log file
        â”œâ”€â”€ events.ndjson        # Event stream
        â”œâ”€â”€ summary.json         # Metrics summary
        â””â”€â”€ iterations/          # Per-iteration logs
```

## ðŸ”„ Data Flow Architecture

### 1. Loop Initialization
```mermaid
task-manager.sh
    â”œâ”€> Parse arguments (--task, --prompt)
    â”œâ”€> Source task module (tasks/[task]/task.sh)
    â”œâ”€> Source loop core (lib/loop.sh)
    â””â”€> Dispatch command via loop_dispatch()
```

### 2. Iteration Execution
```mermaid
loop_dispatch("run-loop")
    â”œâ”€> Initialize environment
    â”œâ”€> Load previous summary
    â”œâ”€> Build prompt
    â”‚   â”œâ”€> Load base prompt
    â”‚   â”œâ”€> Inject summary context
    â”‚   â””â”€> Add helper context
    â”œâ”€> Execute worker
    â”‚   â”œâ”€> Spawn Claude Code process
    â”‚   â”œâ”€> Monitor execution
    â”‚   â””â”€> Capture output
    â”œâ”€> Process results
    â”‚   â”œâ”€> Extract summary
    â”‚   â”œâ”€> Log events
    â”‚   â””â”€> Update metrics
    â””â”€> Check continuation
        â””â”€> Repeat or terminate
```

### 3. Worker Execution Model
```bash
# Worker process hierarchy
loop.sh (manager)
  â””â”€> worker_wrapper.sh (isolation layer)
      â””â”€> claude (actual work)
          â””â”€> vrooli/docker/etc (system commands)
```

## ðŸŽ›ï¸ Core Components

### Loop Core (`lib/loop.sh`)
**Purpose**: Generic iteration engine that can run any task type

**Key Functions**:
- `loop_dispatch()` - Main command router
- `run_loop()` - Iteration orchestrator
- `run_once()` - Single iteration executor

**Design Principles**:
- Task-agnostic execution
- Modular hook system
- Graceful failure handling
- Process isolation

### Task Modules (`tasks/*/task.sh`)
**Purpose**: Define task-specific behavior through hooks

**Required Hooks**:
```bash
# Define task name
LOOP_TASK="task-name"

# Return prompt file candidates
task_prompt_candidates()

# Build helper context for prompt
task_build_helper_context()

# Compose final prompt
task_build_prompt()

# Check worker prerequisites
task_check_worker_available()

# Prepare worker environment
task_prepare_worker_env()

# Execute worker with prompt
task_run_worker()
```

### Process Management (`lib/process.sh`)
**Purpose**: Robust process lifecycle management

**Features**:
- PID tracking and cleanup
- Signal handling (TERM, INT, HUP)
- Lock file management
- Zombie process prevention
- Graceful shutdown sequencing

### Worker Management (`lib/workers.sh`)
**Purpose**: Isolate and control Claude Code execution

**Key Features**:
- Timeout enforcement
- Output redaction (secrets, keys)
- Resource limits
- TCP connection gating
- Concurrent worker limiting

### Event System (`lib/events.sh`)
**Purpose**: Track all loop activities for analysis

**Event Schema**:
```json
{
  "timestamp": "ISO-8601",
  "event": "iteration_start|iteration_end|error|warning",
  "iteration": 1,
  "task": "resource-improvement",
  "duration": 300,
  "exit_code": 0,
  "details": {}
}
```

## ðŸ” Security Architecture

### Process Isolation
```bash
# Each worker runs in isolation
Worker Process
  â”œâ”€> Separate process group
  â”œâ”€> Timeout enforcement
  â”œâ”€> Resource limits
  â””â”€> Output sanitization
```

### Secret Management
```bash
# Redaction pipeline
Worker Output
  â””â”€> Redaction Filter
      â”œâ”€> API keys (sk-*, api_*)
      â”œâ”€> Passwords
      â”œâ”€> Tokens
      â””â”€> Clean output
```


## ðŸ“Š Metrics Architecture

### Collection Points
```
Worker Start â†’ Event Log â†’ Duration Calculation â†’ Summary Generation
     â†“             â†“                â†“                    â†“
  Timestamp    NDJSON Log      Execution Time      JSON/TXT Summary
```

### Metric Types
```yaml
efficiency_metrics:
  - iterations_per_hour
  - success_rate
  - average_duration
  - resource_utilization

progress_metrics:
  - prd_completion_percentage
  - issues_fixed
  - resources_improved
  - scenarios_validated

quality_metrics:
  - validation_pass_rate
  - rollback_frequency
  - error_rate
  - drift_coefficient
```

## ðŸ”„ State Management

### Persistent State
```bash
data/[task]/
â”œâ”€â”€ loop.pid          # Current process
â”œâ”€â”€ loop.lock         # Mutex lock
â”œâ”€â”€ workers.pids      # Active workers
â””â”€â”€ summary.json      # Cumulative metrics
```

### Iteration Context
```bash
# Context flow between iterations
Iteration N-1 Summary
    â†“
Iteration N Prompt
    â†“
Iteration N Execution
    â†“
Iteration N Summary
    â†“
Iteration N+1 Prompt
```

### Lock Management
```bash
# Prevents concurrent execution
start_loop()
  â”œâ”€> Acquire lock (loop.lock)
  â”œâ”€> Write PID (loop.pid)
  â”œâ”€> Execute iterations
  â””â”€> Release lock on exit
```

## ðŸš¦ Control Flow

### Normal Execution
```
START â†’ Initialize â†’ Loop[
  Select Target â†’
  Build Prompt â†’
  Execute Worker â†’
  Process Results â†’
  Check Continuation
] â†’ Cleanup â†’ END
```

### Error Recovery
```
ERROR â†’ Capture State â†’ Log Event â†’ 
  â”œâ”€[Recoverable] â†’ Continue Loop
  â””â”€[Fatal] â†’ Cleanup â†’ EXIT
```

### Signal Handling
```
SIGTERM/SIGINT â†’ 
  â”œâ”€> Stop accepting new iterations
  â”œâ”€> Finish current iteration
  â”œâ”€> Kill workers gracefully
  â”œâ”€> Cleanup resources
  â””â”€> Exit cleanly
```

## ðŸ”§ Configuration System

### Environment Variables
```bash
# Core configuration
LOOP_TASK              # Task identifier
INTERVAL_SECONDS       # Delay between iterations
MAX_ITERATIONS         # Loop termination
TIMEOUT               # Worker timeout

# Advanced configuration
MAX_CONCURRENT_WORKERS # Parallelism limit
MAX_TCP_CONNECTIONS   # Network throttling
LOOP_TCP_FILTER       # Process filter
OLLAMA_SUMMARY_MODEL  # NL summary generation

# Task-specific
PROMPT_PATH               # Custom prompt override
```

### Configuration Precedence
```
1. Command-line arguments (highest)
2. Environment variables
3. Task defaults
4. System defaults (lowest)
```

## ðŸ”Œ Extension Points

### Adding New Tasks
```bash
# 1. Create task structure
tasks/my-task/
â”œâ”€â”€ task.sh           # Implement hooks
â””â”€â”€ prompts/
    â””â”€â”€ my-task.md    # Define prompt

# 2. Implement required hooks in task.sh
LOOP_TASK="my-task"
task_prompt_candidates() { ... }
task_build_helper_context() { ... }
# ... other hooks

# 3. Use via task-manager
./task-manager.sh --task my-task start
```

### Custom Selection Tools
```bash
tools/selection/my-selector.sh
# Output: Newline-separated candidates
# Input: JSON via stdin or file
# Logic: Priority scoring algorithm
```

### Worker Customization
```bash
# Override worker behavior in task.sh
task_run_worker() {
    local prompt="$1"
    local iteration="$2"
    
    # Custom worker logic
    my_custom_worker "$prompt"
}
```

## ðŸŽ¨ Design Patterns

### 1. Hook Pattern
**Purpose**: Extensibility without modification
```bash
# Core calls hook if defined
if declare -f task_hook >/dev/null; then
    task_hook "$args"
fi
```

### 2. Pipeline Pattern
**Purpose**: Composable data processing
```bash
get_data | transform | filter | output
```

### 3. Guard Pattern
**Purpose**: Defensive programming
```bash
[[ -n "${VAR:-}" ]] || die "VAR required"
```

### 4. Singleton Pattern
**Purpose**: Prevent multiple instances
```bash
acquire_lock || die "Already running"
```

## ðŸ”¬ Performance Characteristics

### Resource Usage
```yaml
cpu:
  idle: <1%
  active: 10-30% (worker dependent)
  
memory:
  base: ~50MB
  per_worker: ~200-500MB
  
disk:
  logs: ~10MB/day
  events: ~1MB/day
  
network:
  api_calls: 50-200/iteration
  bandwidth: ~1-10MB/iteration
```

### Scalability Limits
```yaml
concurrent_workers: 5 (configurable)
iterations_per_day: ~288 (5-min intervals)
max_continuous_runtime: weeks
log_rotation: automatic
```

## ðŸš€ Optimization Opportunities

### Current Bottlenecks
1. **Sequential iteration execution** - Could parallelize independent targets
2. **Summary generation latency** - Could pre-compute while worker runs
3. **Log parsing overhead** - Could use structured logging
4. **Selection algorithm** - Could cache scores

### Future Enhancements
1. **Distributed execution** - Run loops across multiple machines
2. **Smart scheduling** - ML-based iteration timing
3. **Incremental summaries** - Stream processing instead of batch
4. **Shared intelligence** - Cross-loop learning database

## ðŸŽ­ Failure Modes

### Graceful Failures
- Worker timeout â†’ Log and continue
- Selection failure â†’ Skip iteration
- Validation failure â†’ Document and move on
- Network issues â†’ Retry with backoff

### Fatal Failures
- Disk full â†’ Emergency shutdown
- Memory exhaustion â†’ Process killed
- Corrupted state â†’ Manual intervention
- Permission denied â†’ Configuration error

## ðŸ” Debugging Architecture

### Log Hierarchy
```
loop.log          # High-level orchestration
â†“
iterations/*.log  # Detailed worker output
â†“
events.ndjson    # Structured event stream
```

### Debug Commands
```bash
# Real-time monitoring
tail -f data/[task]/loop.log

# Event analysis
jq '.event == "error"' data/[task]/events.ndjson

# Performance profiling
jq '.duration' data/[task]/events.ndjson | stats

# State inspection
cat data/[task]/summary.json | jq
```

## ðŸ“š Architecture Principles

1. **Modularity**: Components are loosely coupled and independently testable
2. **Resilience**: Failures in one iteration don't affect others
3. **Observability**: Every action is logged and measurable
4. **Extensibility**: New tasks can be added without core changes
5. **Simplicity**: Bash-based for transparency and debuggability
6. **Isolation**: Worker processes can't affect the loop manager
7. **Idempotency**: Iterations can be safely retried
8. **Convergence**: System progresses toward goal despite failures

## ðŸŽ¬ Conclusion

The auto/ architecture implements a robust, extensible framework for orchestrating AI-driven development loops. Its modular design, comprehensive error handling, and metrics-driven approach enable reliable autonomous operation over extended periods, bootstrapping Vrooli's resources and scenarios toward true autonomy.
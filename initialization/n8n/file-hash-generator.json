{
  "name": "Universal File Hash Generator",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "file-hash",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook_trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1.1,
      "position": [200, 200]
    },
    {
      "parameters": {},
      "id": "manual_trigger",
      "name": "Manual Trigger",
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [200, 400]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const input = $input.item.json;\nif (!input || Object.keys(input).length === 0 || !input.action) {\n  return {\n    action: \"generate_hash\",\n    content: \"Hello, world! This is a test string for hash generation.\",\n    algorithm: \"sha256\",\n    output_format: \"hex\",\n    test_mode: true\n  };\n}\nreturn input;"
      },
      "id": "handle_empty_input",
      "name": "Handle Empty Input (Manual Only)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [380, 400]
    },
    {
      "parameters": {},
      "id": "merge_triggers",
      "name": "Merge Triggers",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 2.1,
      "position": [520, 300]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Validate input and prepare hash generation data\nconst input = $input.item.json;\n\n// Validate required action field\nif (!input.action) {\n  throw new Error('Missing required field: action');\n}\n\nconst validActions = ['generate_hash', 'verify_hash', 'batch_hash', 'compare_files'];\nif (!validActions.includes(input.action)) {\n  throw new Error(`Invalid action: ${input.action}. Valid actions: ${validActions.join(', ')}`);\n}\n\n// Validate algorithm\nconst algorithm = input.algorithm || 'sha256';\nconst validAlgorithms = ['md5', 'sha1', 'sha256', 'sha512'];\nif (!validAlgorithms.includes(algorithm.toLowerCase())) {\n  throw new Error(`Invalid algorithm: ${algorithm}. Valid algorithms: ${validAlgorithms.join(', ')}`);\n}\n\n// Validate output format\nconst outputFormat = input.output_format || 'hex';\nconst validFormats = ['hex', 'base64'];\nif (!validFormats.includes(outputFormat.toLowerCase())) {\n  throw new Error(`Invalid output format: ${outputFormat}. Valid formats: ${validFormats.join(', ')}`);\n}\n\n// Validate input data based on action\nif (['generate_hash'].includes(input.action)) {\n  if (!input.content && !input.file_data) {\n    throw new Error(`Action '${input.action}' requires either 'content' or 'file_data'`);\n  }\n}\n\nif (['verify_hash'].includes(input.action)) {\n  if (!input.expected_hash) {\n    throw new Error(`Action '${input.action}' requires 'expected_hash'`);\n  }\n  if (!input.content && !input.file_data) {\n    throw new Error(`Action '${input.action}' requires either 'content' or 'file_data'`);\n  }\n}\n\nif (['batch_hash'].includes(input.action)) {\n  if (!input.items || !Array.isArray(input.items)) {\n    throw new Error(`Action '${input.action}' requires 'items' array`);\n  }\n  if (input.items.length === 0) {\n    throw new Error('Items array cannot be empty');\n  }\n}\n\nif (['compare_files'].includes(input.action)) {\n  if (!input.file1_data || !input.file2_data) {\n    throw new Error(`Action '${input.action}' requires both 'file1_data' and 'file2_data'`);\n  }\n}\n\n// Prepare hash generation data\nconst hashData = {\n  action: input.action,\n  algorithm: algorithm.toLowerCase(),\n  output_format: outputFormat.toLowerCase(),\n  content: input.content || null,\n  file_data: input.file_data || null,\n  expected_hash: input.expected_hash || null,\n  items: input.items || [],\n  file1_data: input.file1_data || null,\n  file2_data: input.file2_data || null,\n  file1_name: input.file1_name || 'file1',\n  file2_name: input.file2_name || 'file2',\n  include_metadata: input.include_metadata !== false,\n  case_sensitive: input.case_sensitive !== false,\n  metadata: {\n    request_id: `hash_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n    trace_id: input.trace_id || null,\n    timestamp: new Date().toISOString(),\n    test_mode: input.test_mode || false\n  }\n};\n\nreturn hashData;"
      },
      "id": "validate_input",
      "name": "Validate Input",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [700, 300]
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "string": [
                  {
                    "value1": "={{ $json.action }}",
                    "value2": "generate_hash"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "generate"
            },
            {
              "conditions": {
                "string": [
                  {
                    "value1": "={{ $json.action }}",
                    "value2": "verify_hash"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "verify"
            },
            {
              "conditions": {
                "string": [
                  {
                    "value1": "={{ $json.action }}",
                    "value2": "batch_hash"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "batch"
            },
            {
              "conditions": {
                "string": [
                  {
                    "value1": "={{ $json.action }}",
                    "value2": "compare_files"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "compare"
            }
          ]
        }
      },
      "id": "action_router",
      "name": "Action Router",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 1,
      "position": [900, 300]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Generate hash for content or file data\nconst input = $input.item.json;\nconst crypto = require('crypto');\n\n// Determine input data\nlet inputData = input.content || input.file_data;\nif (!inputData) {\n  throw new Error('No input data provided for hash generation');\n}\n\n// Convert to buffer if it's a string\nlet buffer;\nif (typeof inputData === 'string') {\n  buffer = Buffer.from(inputData, 'utf8');\n} else if (inputData instanceof Buffer) {\n  buffer = inputData;\n} else {\n  // Assume it's binary data and convert\n  buffer = Buffer.from(inputData);\n}\n\n// Generate hash\nconst hash = crypto.createHash(input.algorithm);\nhash.update(buffer);\n\n// Get hash in requested format\nlet hashValue;\nif (input.output_format === 'base64') {\n  hashValue = hash.digest('base64');\n} else {\n  hashValue = hash.digest('hex');\n}\n\n// Calculate additional metadata\nconst inputSize = buffer.length;\nconst hashLength = hashValue.length;\n\n// Estimate hash strength (simplified)\nconst strengthMap = {\n  'md5': { bits: 128, strength: 'weak', recommendation: 'Consider using SHA-256 or higher' },\n  'sha1': { bits: 160, strength: 'deprecated', recommendation: 'Upgrade to SHA-256 or SHA-512' },\n  'sha256': { bits: 256, strength: 'strong', recommendation: 'Excellent choice for most use cases' },\n  'sha512': { bits: 512, strength: 'very strong', recommendation: 'Optimal for high-security applications' }\n};\n\nconst algorithmInfo = strengthMap[input.algorithm] || strengthMap['sha256'];\n\n// Prepare response\nconst response = {\n  success: true,\n  action: 'generate_hash',\n  hash_result: {\n    algorithm: input.algorithm,\n    hash_value: hashValue,\n    output_format: input.output_format,\n    input_size_bytes: inputSize,\n    hash_length: hashLength\n  },\n  algorithm_info: {\n    ...algorithmInfo,\n    collision_resistance: input.algorithm === 'md5' ? 'compromised' :\n                         input.algorithm === 'sha1' ? 'weakened' : 'strong'\n  },\n  integrity_check: {\n    can_verify_integrity: true,\n    recommended_uses: input.algorithm === 'md5' ? ['checksums', 'non-security applications'] :\n                      input.algorithm === 'sha1' ? ['legacy compatibility only'] :\n                      ['digital signatures', 'certificates', 'password storage', 'data integrity']\n  },\n  performance_stats: {\n    processing_time_estimate_ms: Math.ceil(inputSize / 1000), // Rough estimate\n    memory_usage_bytes: inputSize + hashLength,\n    suitable_for_large_files: input.algorithm !== 'md5'\n  },\n  metadata: {\n    ...input.metadata,\n    processing_time_ms: 3,\n    input_type: input.content ? 'text' : 'binary'\n  }\n};\n\nreturn response;"
      },
      "id": "generate_hash",
      "name": "Generate Hash",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [1100, 100]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Verify hash against expected value\nconst input = $input.item.json;\nconst crypto = require('crypto');\n\n// Determine input data\nlet inputData = input.content || input.file_data;\nif (!inputData) {\n  throw new Error('No input data provided for hash verification');\n}\n\n// Convert to buffer if it's a string\nlet buffer;\nif (typeof inputData === 'string') {\n  buffer = Buffer.from(inputData, 'utf8');\n} else if (inputData instanceof Buffer) {\n  buffer = inputData;\n} else {\n  buffer = Buffer.from(inputData);\n}\n\n// Generate actual hash\nconst hash = crypto.createHash(input.algorithm);\nhash.update(buffer);\n\nlet actualHash;\nif (input.output_format === 'base64') {\n  actualHash = hash.digest('base64');\n} else {\n  actualHash = hash.digest('hex');\n}\n\n// Normalize expected hash for comparison\nlet expectedHash = input.expected_hash;\nif (input.case_sensitive === false) {\n  actualHash = actualHash.toLowerCase();\n  expectedHash = expectedHash.toLowerCase();\n}\n\n// Verify hash match\nconst isMatch = actualHash === expectedHash;\nconst hashDistance = isMatch ? 0 : \n  Math.abs(actualHash.length - expectedHash.length) + \n  (actualHash.split('').filter((char, i) => char !== expectedHash[i]).length);\n\n// Analyze the verification result\nconst analysis = {\n  integrity_status: isMatch ? 'intact' : 'compromised',\n  confidence_level: isMatch ? 'absolute' : 'none',\n  tamper_detection: !isMatch,\n  hash_format_match: actualHash.length === expectedHash.length\n};\n\n// Security implications\nconst securityImplications = {\n  data_integrity: isMatch ? 'verified' : 'failed',\n  potential_tampering: !isMatch,\n  recommended_action: isMatch ? 'proceed' : 'investigate',\n  risk_level: isMatch ? 'none' : 'high'\n};\n\n// Generate recommendations\nconst recommendations = {\n  immediate: !isMatch ? [\n    'Hash verification failed - data may be corrupted or tampered',\n    'Do not trust this data for critical operations',\n    'Investigate source of data modification'\n  ] : [\n    'Hash verification successful - data integrity confirmed'\n  ],\n  security: !isMatch ? [\n    'Consider re-downloading or re-generating the original data',\n    'Check for transmission errors or storage corruption',\n    'Implement additional verification layers if possible'\n  ] : []\n};\n\nconst response = {\n  success: true,\n  action: 'verify_hash',\n  verification_result: {\n    is_match: isMatch,\n    expected_hash: expectedHash,\n    actual_hash: actualHash,\n    algorithm: input.algorithm,\n    output_format: input.output_format,\n    hash_distance: hashDistance\n  },\n  analysis: analysis,\n  security_implications: securityImplications,\n  file_stats: {\n    size_bytes: buffer.length,\n    algorithm_strength: input.algorithm === 'md5' ? 'weak' :\n                       input.algorithm === 'sha1' ? 'deprecated' :\n                       input.algorithm === 'sha256' ? 'strong' : 'very strong'\n  },\n  recommendations: recommendations,\n  metadata: {\n    ...input.metadata,\n    processing_time_ms: 4,\n    verification_timestamp: new Date().toISOString()\n  }\n};\n\nreturn response;"
      },
      "id": "verify_hash",
      "name": "Verify Hash",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [1100, 250]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Process batch hash generation\nconst input = $input.item.json;\nconst crypto = require('crypto');\nconst items = input.items;\n\nconst results = [];\nlet totalBytes = 0;\nlet successCount = 0;\nlet errorCount = 0;\n\n// Process each item\nfor (let i = 0; i < items.length; i++) {\n  const item = items[i];\n  \n  try {\n    // Validate item structure\n    if (!item.content && !item.file_data) {\n      throw new Error('Item must have either content or file_data');\n    }\n    \n    // Determine input data\n    let inputData = item.content || item.file_data;\n    let buffer;\n    \n    if (typeof inputData === 'string') {\n      buffer = Buffer.from(inputData, 'utf8');\n    } else if (inputData instanceof Buffer) {\n      buffer = inputData;\n    } else {\n      buffer = Buffer.from(inputData);\n    }\n    \n    // Use item-specific algorithm or default\n    const algorithm = item.algorithm || input.algorithm;\n    const outputFormat = item.output_format || input.output_format;\n    \n    // Generate hash\n    const hash = crypto.createHash(algorithm);\n    hash.update(buffer);\n    \n    let hashValue;\n    if (outputFormat === 'base64') {\n      hashValue = hash.digest('base64');\n    } else {\n      hashValue = hash.digest('hex');\n    }\n    \n    totalBytes += buffer.length;\n    successCount++;\n    \n    results.push({\n      index: i,\n      name: item.name || `item_${i}`,\n      success: true,\n      hash: hashValue,\n      algorithm: algorithm,\n      output_format: outputFormat,\n      size_bytes: buffer.length,\n      content_type: item.content ? 'text' : 'binary',\n      processing_time_ms: Math.ceil(buffer.length / 10000) + 1\n    });\n    \n  } catch (error) {\n    errorCount++;\n    \n    results.push({\n      index: i,\n      name: item.name || `item_${i}`,\n      success: false,\n      error: error.message,\n      algorithm: item.algorithm || input.algorithm,\n      size_bytes: 0\n    });\n  }\n}\n\n// Calculate batch statistics\nconst batchStats = {\n  total_items: items.length,\n  successful: successCount,\n  failed: errorCount,\n  success_rate: (successCount / items.length * 100).toFixed(2) + '%',\n  total_bytes_processed: totalBytes,\n  average_size_bytes: successCount > 0 ? Math.round(totalBytes / successCount) : 0\n};\n\n// Performance analysis\nconst performanceAnalysis = {\n  estimated_total_time_ms: results.reduce((sum, r) => sum + (r.processing_time_ms || 0), 0),\n  average_processing_speed_mb_per_sec: totalBytes > 0 ? \n    (totalBytes / 1024 / 1024) / (batchStats.estimated_total_time_ms / 1000) : 0,\n  memory_efficiency: 'good', // Would calculate based on actual memory usage\n  recommended_batch_size: items.length > 100 ? 'Consider smaller batches for better memory management' :\n                          items.length < 10 ? 'Batch size is efficient' : 'Optimal batch size'\n};\n\n// Algorithm distribution\nconst algorithmDistribution = {};\nresults.forEach(r => {\n  if (r.success) {\n    algorithmDistribution[r.algorithm] = (algorithmDistribution[r.algorithm] || 0) + 1;\n  }\n});\n\nconst response = {\n  success: true,\n  action: 'batch_hash',\n  batch_summary: batchStats,\n  performance_analysis: performanceAnalysis,\n  algorithm_distribution: algorithmDistribution,\n  detailed_results: results,\n  failed_items: results.filter(r => !r.success).map(r => ({\n    index: r.index,\n    name: r.name,\n    error: r.error\n  })),\n  security_notes: {\n    mixed_algorithms: Object.keys(algorithmDistribution).length > 1,\n    weak_algorithms_used: results.some(r => r.success && ['md5', 'sha1'].includes(r.algorithm)),\n    recommended_algorithm: 'sha256',\n    batch_integrity: errorCount === 0 ? 'all_items_processed' : 'partial_failures'\n  },\n  metadata: {\n    ...input.metadata,\n    processing_time_ms: 12,\n    batch_size: items.length\n  }\n};\n\nreturn response;"
      },
      "id": "process_batch",
      "name": "Process Batch",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [1100, 400]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Compare two files using hash comparison\nconst input = $input.item.json;\nconst crypto = require('crypto');\n\n// Process first file\nlet file1Data = input.file1_data;\nlet buffer1;\nif (typeof file1Data === 'string') {\n  buffer1 = Buffer.from(file1Data, 'utf8');\n} else if (file1Data instanceof Buffer) {\n  buffer1 = file1Data;\n} else {\n  buffer1 = Buffer.from(file1Data);\n}\n\n// Process second file\nlet file2Data = input.file2_data;\nlet buffer2;\nif (typeof file2Data === 'string') {\n  buffer2 = Buffer.from(file2Data, 'utf8');\n} else if (file2Data instanceof Buffer) {\n  buffer2 = file2Data;\n} else {\n  buffer2 = Buffer.from(file2Data);\n}\n\n// Generate hashes for both files using multiple algorithms\nconst algorithms = ['md5', 'sha1', 'sha256', 'sha512'];\nconst file1Hashes = {};\nconst file2Hashes = {};\n\nalgorithms.forEach(algorithm => {\n  // Hash file 1\n  const hash1 = crypto.createHash(algorithm);\n  hash1.update(buffer1);\n  file1Hashes[algorithm] = {\n    hex: hash1.digest('hex'),\n    base64: crypto.createHash(algorithm).update(buffer1).digest('base64')\n  };\n  \n  // Hash file 2\n  const hash2 = crypto.createHash(algorithm);\n  hash2.update(buffer2);\n  file2Hashes[algorithm] = {\n    hex: hash2.digest('hex'),\n    base64: crypto.createHash(algorithm).update(buffer2).digest('base64')\n  };\n});\n\n// Compare hashes\nconst hashComparisons = {};\nlet overallMatch = true;\n\nalgorithms.forEach(algorithm => {\n  const hexMatch = file1Hashes[algorithm].hex === file2Hashes[algorithm].hex;\n  const base64Match = file1Hashes[algorithm].base64 === file2Hashes[algorithm].base64;\n  \n  hashComparisons[algorithm] = {\n    hex_match: hexMatch,\n    base64_match: base64Match,\n    consistent: hexMatch === base64Match // Should always be true\n  };\n  \n  if (!hexMatch) overallMatch = false;\n});\n\n// File statistics\nconst file1Stats = {\n  name: input.file1_name,\n  size_bytes: buffer1.length,\n  content_type: typeof input.file1_data === 'string' ? 'text' : 'binary'\n};\n\nconst file2Stats = {\n  name: input.file2_name,\n  size_bytes: buffer2.length,\n  content_type: typeof input.file2_data === 'string' ? 'text' : 'binary'\n};\n\n// Size comparison\nconst sizeComparison = {\n  same_size: buffer1.length === buffer2.length,\n  size_difference_bytes: Math.abs(buffer1.length - buffer2.length),\n  size_difference_percent: buffer1.length > 0 ? \n    (Math.abs(buffer1.length - buffer2.length) / Math.max(buffer1.length, buffer2.length) * 100).toFixed(2) + '%' : '0%',\n  larger_file: buffer1.length > buffer2.length ? input.file1_name : \n               buffer2.length > buffer1.length ? input.file2_name : 'same'\n};\n\n// Analysis and recommendations\nconst analysis = {\n  files_identical: overallMatch,\n  hash_consistency: algorithms.every(alg => hashComparisons[alg].consistent),\n  size_match: sizeComparison.same_size,\n  confidence_level: overallMatch ? 'absolute' : 'certain_different',\n  recommended_algorithm: 'sha256' // Most balanced security/performance\n};\n\nconst recommendations = {\n  integrity: overallMatch ? [\n    'Files are identical - all hash algorithms confirm match',\n    'Data integrity verified across multiple hash functions'\n  ] : [\n    'Files differ - hash comparison confirms different content',\n    'Files cannot be used interchangeably'\n  ],\n  security: !sizeComparison.same_size ? [\n    'Size difference detected - files have different content lengths',\n    'Consider byte-by-byte comparison for detailed differences'\n  ] : overallMatch ? [] : [\n    'Same size but different hashes - content has been modified',\n    'Possible data corruption or intentional changes detected'\n  ],\n  performance: [\n    `Comparison used ${algorithms.length} hash algorithms for maximum confidence`,\n    'SHA-256 recommended for future single-algorithm comparisons'\n  ]\n};\n\nconst response = {\n  success: true,\n  action: 'compare_files',\n  comparison_result: {\n    files_identical: overallMatch,\n    hash_comparisons: hashComparisons,\n    primary_algorithm_result: {\n      algorithm: 'sha256',\n      match: hashComparisons.sha256.hex_match,\n      file1_hash: file1Hashes.sha256.hex,\n      file2_hash: file2Hashes.sha256.hex\n    }\n  },\n  file_details: {\n    file1: {\n      ...file1Stats,\n      hashes: file1Hashes\n    },\n    file2: {\n      ...file2Stats,\n      hashes: file2Hashes\n    }\n  },\n  size_comparison: sizeComparison,\n  analysis: analysis,\n  recommendations: recommendations,\n  verification_matrix: {\n    algorithms_tested: algorithms.length,\n    consistent_results: algorithms.every(alg => hashComparisons[alg].hex_match === overallMatch),\n    strongest_algorithm: 'sha512',\n    fastest_algorithm: 'md5',\n    recommended_algorithm: 'sha256'\n  },\n  metadata: {\n    ...input.metadata,\n    processing_time_ms: 8,\n    total_bytes_compared: buffer1.length + buffer2.length\n  }\n};\n\nreturn response;"
      },
      "id": "compare_files",
      "name": "Compare Files",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [1100, 550]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify($json) }}"
      },
      "id": "success_response",
      "name": "Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1600, 350]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseCode": 400,
        "responseBody": "{\n  \"success\": false,\n  \"error\": \"={{ $json.error || 'Hash generation failed' }}\",\n  \"action\": \"={{ $json.action || 'unknown' }}\",\n  \"algorithm\": \"={{ $json.algorithm || 'unknown' }}\",\n  \"timestamp\": \"={{ new Date().toISOString() }}\"\n}"
      },
      "id": "error_response",
      "name": "Error Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1600, 550]
    },
    {
      "parameters": {
        "values": {
          "string": [
            {
              "name": "output_type",
              "value": "Universal File Hash Generator Complete"
            }
          ]
        },
        "options": {}
      },
      "id": "final_output",
      "name": "Final Output",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [1800, 450]
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Merge Triggers",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Manual Trigger": {
      "main": [
        [
          {
            "node": "Handle Empty Input (Manual Only)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Handle Empty Input (Manual Only)": {
      "main": [
        [
          {
            "node": "Merge Triggers",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Triggers": {
      "main": [
        [
          {
            "node": "Validate Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Input": {
      "main": [
        [
          {
            "node": "Action Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Action Router": {
      "main": [
        [
          {
            "node": "Generate Hash",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Verify Hash",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Process Batch",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Compare Files",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Hash": {
      "main": [
        [
          {
            "node": "Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Verify Hash": {
      "main": [
        [
          {
            "node": "Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process Batch": {
      "main": [
        [
          {
            "node": "Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Compare Files": {
      "main": [
        [
          {
            "node": "Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Success Response": {
      "main": [
        [
          {
            "node": "Final Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Error Response": {
      "main": [
        [
          {
            "node": "Final Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "file-hash-generator-v1.0.0",
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "id": "file-hash-generator",
  "tags": [
    {
      "createdAt": "2025-01-14T00:00:00.000Z",
      "updatedAt": "2025-01-14T00:00:00.000Z",
      "id": "shared-utility",
      "name": "shared-utility"
    },
    {
      "createdAt": "2025-01-14T00:00:00.000Z",
      "updatedAt": "2025-01-14T00:00:00.000Z",
      "id": "hash-generation",
      "name": "hash-generation"
    },
    {
      "createdAt": "2025-01-14T00:00:00.000Z",
      "updatedAt": "2025-01-14T00:00:00.000Z",
      "id": "file-integrity",
      "name": "file-integrity"
    },
    {
      "createdAt": "2025-01-14T00:00:00.000Z",
      "updatedAt": "2025-01-14T00:00:00.000Z",
      "id": "cryptography",
      "name": "cryptography"
    }
  ]
}
#!/usr/bin/env bash
# Simplified Ollama Mock for Resource Testing
# 
# Provides basic Ollama command mocking for testing resource functionality
# Focus: API health checks, model operations, generation testing
#
# NAMING CONVENTIONS: This mock follows the standard naming pattern expected
# by the convention-based resource testing framework:
#
#   test_ollama_connection() : Test API connectivity via model listing
#   test_ollama_health()     : Test API health endpoints
#   test_ollama_basic()      : Test basic text generation functionality
#
# This allows the testing framework to automatically discover and run these
# tests without requiring hardcoded knowledge of Ollama specifics.

# Mock ollama command
ollama() {
    case "$1" in
        "list"|"ls")
            echo "NAME              ID           SIZE    MODIFIED"
            echo "llama2:latest     8934d96d3f08 3.8 GB  2 weeks ago"
            echo "nomic-embed-text  0a109f422b47 274 MB  3 days ago"
            return 0
            ;;
        "pull")
            local model_name="${2:-llama2}"
            echo "pulling manifest"
            echo "pulling $model_name... 100%"
            echo "verifying sha256 digest"
            echo "writing manifest"
            echo "removing any unused layers"
            echo "success"
            return 0
            ;;
        "run")
            local model_name="${2:-llama2}"
            local prompt="${3:-Hello}"
            echo "Mock response from $model_name: This is a test response to: $prompt"
            return 0
            ;;
        "show")
            local model_name="${2:-llama2}"
            echo "# Modelfile generated by \"ollama show\""
            echo "FROM /path/to/$model_name"
            echo ""
            echo "TEMPLATE \"[INST] {{ .System }} {{ .Prompt }} [/INST]\""
            echo ""
            echo "PARAMETER stop \"[INST]\""
            echo "PARAMETER stop \"[/INST]\""
            return 0
            ;;
        "rm"|"remove")
            local model_name="${2:-llama2}"
            echo "deleted '$model_name'"
            return 0
            ;;
        "cp"|"copy")
            local source="${2:-llama2}"
            local dest="${3:-llama2-copy}"
            echo "copied '$source' to '$dest'"
            return 0
            ;;
        "create")
            local model_name="${2:-custom-model}"
            echo "transferring model data"
            echo "creating model layer"
            echo "success"
            return 0
            ;;
        "serve")
            echo "Ollama server starting..."
            echo "Listening on 127.0.0.1:11434 (version 0.1.0)"
            return 0
            ;;
        "version"|"--version")
            echo "ollama version is 0.1.0"
            return 0
            ;;
        *)
            echo "Usage: ollama [command]"
            echo ""
            echo "Available Commands:"
            echo "  serve         Start ollama"
            echo "  create        Create a model from a Modelfile"
            echo "  show          Show information for a model"
            echo "  run           Run a model"
            echo "  pull          Pull a model from a registry"
            echo "  list          List models"
            echo "  cp            Copy a model"
            echo "  rm            Remove a model"
            echo ""
            echo "Use \"ollama [command] --help\" for more information about a command."
            return 0
            ;;
    esac
}

# Mock curl for Ollama API endpoints
mock_ollama_curl() {
    case "$*" in
        # Health check endpoint
        *"/health"*)
            echo "healthy"
            return 0
            ;;
        # Version endpoint
        *"/api/version"*)
            echo '{"version":"0.1.0"}'
            return 0
            ;;
        # List models endpoint
        *"/api/tags"*)
            echo '{
              "models": [
                {
                  "name": "llama2:latest",
                  "modified_at": "2024-01-01T12:00:00.000000000Z",
                  "size": 3791730596,
                  "digest": "8934d96d3f08b9d4c6a4e5e1bb0ce7b8e8b4e1f7f8e4e1f7f8e4e1f7f8e4e1f7"
                },
                {
                  "name": "nomic-embed-text:latest", 
                  "modified_at": "2024-01-01T12:00:00.000000000Z",
                  "size": 274301698,
                  "digest": "0a109f422b47c4e1f7f8e4e1f7f8e4e1f7f8e4e1f7f8e4e1f7f8e4e1f7f8e4e1"
                }
              ]
            }'
            return 0
            ;;
        # Generate endpoint
        *"/api/generate"*)
            echo '{
              "model": "llama2",
              "created_at": "2024-01-01T12:00:00.000000000Z",
              "response": "Hello! This is a mock response from Ollama.",
              "done": true,
              "context": [1, 2, 3],
              "total_duration": 1000000000,
              "load_duration": 100000000,
              "prompt_eval_count": 10,
              "prompt_eval_duration": 200000000,
              "eval_count": 25,
              "eval_duration": 700000000
            }'
            return 0
            ;;
        # Pull endpoint
        *"/api/pull"*)
            echo '{"status":"downloading","completed":0,"total":3791730596}'
            echo '{"status":"downloading","completed":1000000000,"total":3791730596}'
            echo '{"status":"downloading","completed":2000000000,"total":3791730596}'
            echo '{"status":"downloading","completed":3791730596,"total":3791730596}'
            echo '{"status":"verifying sha256 digest"}'
            echo '{"status":"writing manifest"}'
            echo '{"status":"removing any unused layers"}'
            echo '{"status":"success"}'
            return 0
            ;;
        # Chat endpoint
        *"/api/chat"*)
            echo '{
              "model": "llama2",
              "created_at": "2024-01-01T12:00:00.000000000Z",
              "message": {
                "role": "assistant",
                "content": "This is a mock chat response from Ollama."
              },
              "done": true,
              "total_duration": 1000000000,
              "load_duration": 100000000,
              "prompt_eval_count": 15,
              "prompt_eval_duration": 300000000,
              "eval_count": 30,
              "eval_duration": 600000000
            }'
            return 0
            ;;
        # Embeddings endpoint
        *"/api/embeddings"*)
            echo '{
              "embedding": [
                0.1, 0.2, 0.3, -0.1, -0.2, 0.4, 0.5, -0.3,
                0.0, 0.1, -0.1, 0.2, -0.2, 0.3, -0.3, 0.4
              ]
            }'
            return 0
            ;;
        # Default - pass through to real curl if it's not an Ollama API call
        *)
            if [[ "$*" =~ localhost:11434|127\.0\.0\.1:11434 ]]; then
                echo '{"error":"endpoint not mocked"}'
                return 1
            else
                # Pass through to real curl for non-Ollama calls
                command curl "$@"
                return $?
            fi
            ;;
    esac
}

# Test functions for resource validation
test_ollama_health() {
    # Simulate health check via API
    local result
    result=$(mock_ollama_curl -s "http://localhost:11434/health" 2>/dev/null)
    
    if [[ "$result" == "healthy" ]]; then
        return 0
    else
        return 1
    fi
}

test_ollama_connection() {
    # Simulate connection test via model listing API
    local result
    result=$(mock_ollama_curl -s "http://localhost:11434/api/tags" 2>/dev/null)
    
    if echo "$result" | grep -q '"models"'; then
        return 0
    else
        return 1
    fi
}


test_ollama_basic() {
    # Simulate basic functionality test via text generation
    local result
    result=$(mock_ollama_curl -X POST "http://localhost:11434/api/generate" \
        -d '{"model":"llama2","prompt":"Test"}' 2>/dev/null)
    
    if echo "$result" | grep -q '"response"'; then
        return 0
    else
        return 1
    fi
}

test_ollama_command() {
    # Test ollama command directly
    ollama list >/dev/null 2>&1
    return $?
}

test_ollama_version() {
    # Test version command
    local result
    result=$(ollama version 2>/dev/null)
    
    if echo "$result" | grep -q "version"; then
        return 0
    else
        return 1
    fi
}

# Override curl for Ollama API calls during testing
# This will be activated when mocks are loaded
curl() {
    if [[ "$*" =~ localhost:11434|127\.0\.0\.1:11434 ]]; then
        mock_ollama_curl "$@"
    else
        command curl "$@"
    fi
}

# Export mock functions
export -f ollama mock_ollama_curl curl
export -f test_ollama_health test_ollama_connection test_ollama_basic 
export -f test_ollama_command test_ollama_version
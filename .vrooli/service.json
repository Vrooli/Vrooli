{
  "$schema": "schemas/service.schema.json",
  "version": "2.0.2",
  "service": {
    "name": "vrooli-dev",
    "displayName": "Vrooli Development Environment",
    "description": "Development environment for building and testing Vrooli scenarios - self-contained apps that extend the intelligence system",
    "version": "2.0.2",
    "type": "development-environment",
    "category": "infrastructure",
    "tags": [
      "ai-platform",
      "agent-swarms",
      "recursive-improvement",
      "automation",
      "intelligence-system",
      "self-improving"
    ],
    "maintainers": [
      {
        "name": "Vrooli Team",
        "email": "team@vrooli.com",
        "url": "https://github.com/Vrooli"
      }
    ],
    "repository": {
      "type": "git",
      "url": "https://github.com/Vrooli/Vrooli",
      "directory": "/"
    },
    "license": "AGPL-3.0-only",
    "homepage": "https://github.com/Vrooli/Vrooli",
    "documentation": "./docs/README.md",
    "support": {
      "email": "team@vrooli.com",
      "issues": "https://github.com/Vrooli/Vrooli/issues"
    }
  },
  "resources": {
    "storage": {
      "postgres": {
        "type": "postgresql",
        "enabled": true,
        "version": "16",
        "required": true,
        "description": "Main application database"
      },
      "redis": {
        "type": "redis",
        "enabled": true,
        "version": "7",
        "required": true,
        "description": "Event bus and caching layer"
      }
    },
    "ai": {
      "ollama": {
        "type": "ollama",
        "enabled": true,
        "required": false,
        "description": "Local AI inference server"
      }
    },
    "automation": {
      "n8n": {
        "type": "n8n",
        "enabled": false,
        "required": false,
        "description": "Workflow automation platform",
        "initialization": [
          {
            "file": "initialization/automation/n8n/embedding-generator.json",
            "type": "workflow",
            "description": "Converts text to embeddings. Useful for storing text in a vector database, such as Qdrant."
},
          {
            "file": "initialization/automation/n8n/structured-data-extractor.json",
            "type": "workflow",
            "description": "Extracts structured data from unstructured text using AI. Supports schema-based extraction, auto-detection of common patterns (emails, phones, dates), and confidence scoring."
          },
          {
            "file": "initialization/automation/n8n/universal-rag-pipeline.json",
            "type": "workflow",
            "description": "Complete RAG pipeline: fetches content (URLs/files/text), chunks it, generates embeddings, and stores in Qdrant or returns for custom storage."
          },
          {
            "file": "initialization/automation/n8n/cache-manager.json",
            "type": "workflow",
            "description": "Universal caching system with Redis multi-database support. Provides GET/SET/DELETE/INVALIDATE/WARM/STATS operations with automatic database selection, compression, tagging, and pattern-based invalidation."
          },
          {
            "file": "initialization/automation/n8n/web-research-aggregator.json",
            "type": "workflow",
            "description": "Smart web research pipeline: search ‚Üí filter ‚Üí extract ‚Üí synthesize. Uses SearXNG + Browserless + Ollama for comprehensive research with configurable strategies and intelligent content processing."
          },
          {
            "file": "initialization/automation/n8n/multi-agent-reasoning-ensemble.json",
            "type": "workflow",
            "description": "Multi-agent reasoning system replicating Grok 4 Heavy functionality. Spawns multiple specialized agents to analyze complex problems, build consensus, and provide high-quality recommendations with confidence scoring and detailed analysis."
          },
          {
            "file": "initialization/automation/n8n/smart-semantic-search.json",
            "type": "workflow",
            "description": "Revolutionary semantic search that generates multiple targeted queries from input text using LLM analysis, executes parallel searches, and aggregates results. Dramatically improves search quality by capturing multi-faceted concepts and specific details that single-embedding approaches miss."
          },
          {
            "file": "initialization/automation/n8n/document-converter-validator.json",
            "type": "workflow",
            "description": "Universal document converter and validator: handles multiple input sources (file/URL/MinIO/content), detects formats using magic numbers, converts between formats (PDF/DOCX‚Üítext/markdown/JSON), validates content quality, and provides comprehensive metadata. Essential foundation for document processing across all scenarios."
          },
          {
            "file": "initialization/automation/n8n/intelligent-text-classifier.json",
            "type": "workflow",
            "description": "Intelligent multi-modal text classification system: PII detection, log severity analysis, content safety, document type identification, sentiment analysis, and custom classification with few-shot learning. Combines rule-based, LLM-based, and embedding-based approaches for high accuracy and speed. Essential for data governance, operational intelligence, and content management across all scenarios."
          },
          {
            "file": "initialization/automation/n8n/workflow-creator-fixer.json",
            "type": "workflow",
            "description": "Meta-workflow for creating and fixing other n8n workflows through iterative AI generation, validation, and testing. Embodies recursive improvement by learning from successes and failures to become better at building workflows over time. Essential for accelerating development, ensuring quality, and enabling self-healing capabilities across all scenarios."
          },
          {
            "file": "initialization/automation/n8n/react-loop-engine.json",
            "type": "workflow",
            "description": "Autonomous agent workflow implementing Reasoning + Acting (ReAct) pattern. Enables agents to iteratively reason about problems, call tools, observe results, and continue until task completion. Foundation for truly autonomous AI agents that can solve complex, multi-step problems."
          },
          {
            "file": "initialization/automation/n8n/tool-calling-orchestrator.json",
            "type": "workflow",
            "description": "Universal function calling system for Ollama models. Bridges the gap between LLM-generated tool calls and actual execution with dynamic tool registry, parameter validation, parallel execution, and comprehensive error handling. Transforms any LLM into a tool-using agent."
          },
          {
            "file": "initialization/automation/n8n/event-stream-hub.json",
            "type": "workflow",
            "description": "Universal pub/sub event streaming using Redis Streams. Provides real-time communication backbone with topic management, event filtering, replay capabilities, consumer groups, and dead letter queues. Essential for event-driven architectures and inter-service communication."
          },
          {
            "file": "initialization/automation/n8n/smart-notification-router.json",
            "type": "workflow",
            "description": "Intelligent multi-channel notification delivery system. Supports email, Slack, webhook, and SMS with priority-based routing, template management, retry logic, and delivery confirmation. Universal notification solution for all scenarios."
          },
          {
            "file": "initialization/automation/n8n/simple-queue-manager.json",
            "type": "workflow",
            "description": "Lightweight async task processing queue using Redis. Provides FIFO and priority queues with job tracking, exponential backoff retry, dead letter queues, and comprehensive monitoring. Essential building block for scalable async processing."
          },
          {
            "file": "initialization/automation/n8n/chain-of-thought-orchestrator.json",
            "type": "workflow",
            "description": "Enforces step-by-step reasoning with validation loops to significantly improve LLM output quality. Multi-stage thinking pipeline with self-critique validation, context preservation, and quality metrics. Transforms free-form responses into structured, validated reasoning."
          },
          {
            "file": "initialization/automation/n8n/agent-conversation-manager.json",
            "type": "workflow",
            "description": "Multi-agent structured conversation system enabling AI agents with different models to debate, collaborate, and build consensus. Supports role-based specializations, round-based discussions, agreement tracking, and conversation synthesis for complex decision-making."
          }
        ]
      },
      "windmill": {
        "type": "windmill",
        "enabled": false,
        "required": false,
        "description": "Developer platform for building automation apps"
      },
      "node-red": {
        "type": "node-red",
        "enabled": false,
        "required": false,
        "description": "Visual programming for IoT and automation"
      }
    },
    "agents": {
      "browserless": {
                "enabled": true,
        "baseUrl": "http://localhost:4110",
        "healthCheck": {
          "intervalMs": 60000,
          "timeoutMs": 5000
        }
      },
      "claude-code": {
        "type": "claude-code",
        "enabled": false,
        "required": false,
        "description": "Claude Code development assistant"
      }
    },
    "search": {
      "searxng": {
        "type": "searxng",
        "enabled": false,
        "required": false,
        "description": "Privacy-respecting search engine"
      }
    }
  },
  "deployment": {
    "target": "docker",
    "strategy": "rolling-update",
    "urls": {
      "application": "http://localhost:3000",
      "api": "http://localhost:3000/api",
      "health": "http://localhost:3000/api/health"
    },
    "monitoring": {
      "enabled": true,
      "healthChecks": {
        "application": {
          "endpoint": "http://localhost:3000/api/health",
          "interval": "30s",
          "timeout": "5s",
          "threshold": 3
        },
        "database": {
          "type": "tcp",
          "port": 5432,
          "interval": "30s"
        },
        "redis": {
          "type": "tcp",
          "port": 6379,
          "interval": "30s"
        }
      }
    }
  },
  "lifecycle": {
    "version": "2.0.2",
    "setup": {
      "description": "Initialize system for scenario development",
      "steps": [
        {
          "name": "base-setup",
          "run": "bash scripts/lib/setup.sh",
          "description": "Execute generic setup (e.g. network, system, git)"
        },
        {
          "name": "install-cli",
          "run": "if [[ -f cli/install.sh ]]; then cli/install.sh; else echo '‚ö†Ô∏è  CLI installer not found, skipping'; fi",
          "description": "Install Vrooli CLI command"
        },
        {
          "name": "add-data",
          "run": "scripts/resources/injection/engine.sh .",
          "description": "Add app data to resources"
        },
        {
          "name": "convert-scenarios",
          "run": "./scripts/scenarios/tools/auto-converter.sh",
          "description": "Convert enabled scenarios to standalone apps",
          "timeout": "5m"
        }
      ]
    },
    "develop": {
      "description": "Prepare development environment",
      "steps": [
        {
          "name": "load-env",
          "run": "[[ -f .env ]] && (echo 'Loading .env file' && set -a && source .env && set +a) || echo 'No .env file found'",
          "description": "Load environment variables from .env if exists"
        },
        {
          "name": "start-api",
          "run": "if [[ -f api/start.sh ]]; then (api/start.sh >/dev/null 2>&1 &) && echo 'üöÄ Vrooli API started on port 8090' || echo '‚ö†Ô∏è  Failed to start API'; else echo '‚ö†Ô∏è  API not found'; fi",
          "description": "Start the Vrooli unified API server"
        },
        {
          "name": "start-generated-apps",
          "run": "./scripts/scenarios/tools/multi-app-runner.sh --verbose",
          "description": "Start all generated apps using the orchestrator",
          "timeout": "10m"
        }
      ]
    },
    "build": {
      "description": "Prepare build environment",
      "steps": [
        {
          "name": "create-directories",
          "run": "mkdir -p build dist",
          "description": "Create build and dist directories"
        },
        {
          "name": "set-build-env",
          "run": "export BUILD_TIME=\"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\" && export BUILD_ENV=\"${ENVIRONMENT:-development}\" && echo \"Build environment: $BUILD_ENV at $BUILD_TIME\"",
          "description": "Set build environment variables"
        }
      ]
    },
    "test": {
      "description": "Run comprehensive test suite",
      "steps": [
        {
          "name": "set-test-env",
          "run": "export NODE_ENV=test CI=${CI:-false} && echo \"Test environment: NODE_ENV=$NODE_ENV, CI=$CI\"",
          "description": "Set test environment variables"
},
        {
          "name": "run-shell-tests",
          "run": "scripts/__test-revised/run-tests.sh all",
          "description": "Execute comprehensive shell test suite (static, resources, scenarios, bats)",
          "timeout": "10m"
        }
      ]
    },
    "deploy": {
      "description": "Deployment preparation",
      "steps": [
        {
          "name": "show-deploy-info",
          "run": "echo 'Scenarios should be deployed individually from their directories'",
          "description": "Deployment information"
        }
      ]
    },
    "clean": {
      "description": "Clean build artifacts and dependencies",
      "steps": [
        {
          "name": "run-clean",
          "run": "rm -rf packages/*/dist packages/*/build packages/*/.next node_modules packages/*/node_modules || true",
          "description": "Remove build artifacts and dependencies"
        }
      ]
    }
  }
}

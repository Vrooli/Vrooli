version: 1.0
scenario: multi-resource-pipeline

# Structure validation
structure:
  required_files:
    - .vrooli/service.json
    - initialization/storage/schema.sql
    - initialization/storage/seed.sql
    - initialization/automation/n8n/main-workflow.json
    - initialization/automation/triggers.yaml
    - initialization/automation/windmill/windmill-app.json
    - initialization/configuration/app-config.json
    - initialization/configuration/feature-flags.json
    - initialization/configuration/resource-urls.json
    - deployment/startup.sh
    - deployment/monitor.sh
    - test.sh
    - custom-tests.sh
  
  required_dirs:
    - .vrooli
    - initialization/storage
    - initialization/automation
    - initialization/configuration
    - deployment

# Resource requirements
resources:
  required: [postgres, ollama, whisper, unstructured-io, qdrant, minio]
  optional: [comfyui]
  health_timeout: 60

# Declarative tests
tests:
  - name: "Application Health Check"
    type: http
    service: app
    endpoint: /api/multi-resource-pipeline/health
    method: GET
    expect:
      status: 200
      body:
        type: json

  - name: "AI Model Engine Ready"
    type: http
    service: ollama
    endpoint: /api/tags
    method: GET
    expect:
      status: 200
      body:
        type: json
        
  - name: "Audio Transcription Engine Ready"
    type: http
    service: whisper
    endpoint: /health
    method: GET
    expect:
      status: 200
      
  - name: "Document Processing Engine Ready"
    type: http
    service: unstructured-io
    endpoint: /general/v0/general
    method: GET
    expect:
      status: 200
      
  - name: "Vector Database Ready"
    type: http
    service: qdrant
    endpoint: /health
    method: GET
    expect:
      status: 200

  - name: "Object Storage Ready"
    type: http
    service: minio
    endpoint: /minio/health/ready
    method: GET
    expect:
      status: 200

  - name: "Database Connection"
    type: tcp
    service: postgres
    port: 5432
        
  - name: "Multi-Format Data Pipeline Workflow"
    type: custom
    script: custom-tests.sh
    function: test_multi_resource_pipeline_workflow

# Validation criteria
validation:
  success_rate: 85        # High success rate for enterprise data pipeline
  response_time: 20000    # 20 seconds max for complex data processing operations
  revenue_potential: 73000  # Total estimate from service.json
  business_criteria:
    - "Unified multi-format data processing pipeline operational"
    - "Document, audio, and structured data ingestion functional"
    - "AI-powered content analysis and embedding generation validated"
    - "Vector search and intelligent data retrieval verified"
    - "Enterprise data engineering capabilities confirmed"

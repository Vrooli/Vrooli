[
  {
    "id": "metric-collector-flow",
    "type": "tab",
    "label": "System Metrics Collector",
    "disabled": false
  },
  {
    "id": "system-metrics-timer",
    "type": "inject",
    "z": "metric-collector-flow",
    "name": "Collect Every 30s",
    "repeat": "30",
    "crontab": "",
    "once": true,
    "topic": "system-metrics"
  },
  {
    "id": "collect-basic-metrics",
    "type": "function",
    "z": "metric-collector-flow",
    "name": "Collect Basic System Metrics",
    "func": "// Collect comprehensive system metrics using Node.js modules\nconst os = global.get('os');\nconst fs = global.get('fs');\nconst process = global.get('process');\n\nconst cpuInfo = os.cpus();\nconst totalMem = os.totalmem();\nconst freeMem = os.freemem();\nconst loadAvg = os.loadavg();\n\n// Calculate CPU usage percentage\nlet totalIdle = 0;\nlet totalTick = 0;\ncpuInfo.forEach(cpu => {\n    for (type in cpu.times) {\n        totalTick += cpu.times[type];\n    }\n    totalIdle += cpu.times.idle;\n});\nconst cpuUsage = Math.round(100 - (100 * totalIdle / totalTick));\n\n// Memory usage percentage\nconst memUsage = Math.round(((totalMem - freeMem) / totalMem) * 100);\n\n// Network interface stats (basic)\nconst networkInterfaces = os.networkInterfaces();\nlet totalRxBytes = 0;\nlet totalTxBytes = 0;\n\n// Try to get network stats from /proc/net/dev (Linux)\ntry {\n    const netStats = fs.readFileSync('/proc/net/dev', 'utf8');\n    const lines = netStats.split('\\n');\n    lines.forEach(line => {\n        if (line.includes(':') && !line.includes('lo:')) {\n            const parts = line.trim().split(/\\s+/);\n            if (parts.length >= 10) {\n                totalRxBytes += parseInt(parts[1]) || 0;\n                totalTxBytes += parseInt(parts[9]) || 0;\n            }\n        }\n    });\n} catch (e) {\n    // Network stats not available\n}\n\n// Disk usage - try to get from /proc/diskstats or estimate\nlet diskUsage = 0;\ntry {\n    const stats = fs.statSync('/');\n    // This is a rough estimation\n    diskUsage = 50; // Default placeholder\n} catch (e) {\n    diskUsage = 0;\n}\n\nmsg.payload = {\n    cpu_usage: cpuUsage,\n    memory_usage: memUsage,\n    memory_total: totalMem,\n    memory_free: freeMem,\n    disk_usage: diskUsage,\n    disk_total: 0, // Will be filled by disk check node\n    network_rx_bytes: totalRxBytes,\n    network_tx_bytes: totalTxBytes,\n    load_average: loadAvg,\n    process_count: 0, // Will be filled by process count node\n    tcp_connections: 0, // Will be filled by TCP count node\n    timestamp: new Date().toISOString(),\n    hostname: os.hostname(),\n    platform: os.platform(),\n    uptime: os.uptime()\n};\n\nreturn msg;",
    "outputs": 1,
    "libs": [
      {"var": "os", "module": "os"},
      {"var": "fs", "module": "fs"},
      {"var": "process", "module": "process"}
    ]
  },
  {
    "id": "get-disk-usage",
    "type": "exec",
    "z": "metric-collector-flow",
    "command": "df -h / | tail -1 | awk '{print $5}' | sed 's/%//'",
    "addpay": false,
    "append": "",
    "useSpawn": "false",
    "timer": "",
    "winHide": false,
    "oldrc": false,
    "name": "Get Disk Usage %"
  },
  {
    "id": "get-process-count",
    "type": "exec",
    "z": "metric-collector-flow",
    "command": "ps aux | wc -l",
    "addpay": false,
    "append": "",
    "useSpawn": "false",
    "timer": "",
    "winHide": false,
    "oldrc": false,
    "name": "Count Running Processes"
  },
  {
    "id": "get-tcp-connections",
    "type": "exec",
    "z": "metric-collector-flow",
    "command": "netstat -an | grep ESTABLISHED | wc -l",
    "addpay": false,
    "append": "",
    "useSpawn": "false",
    "timer": "",
    "winHide": false,
    "oldrc": false,
    "name": "Count TCP Connections"
  },
  {
    "id": "merge-metrics",
    "type": "function",
    "z": "metric-collector-flow",
    "name": "Merge All Metrics",
    "func": "// Collect all metrics from different sources\nconst baseMetrics = msg.payload;\n\n// Get disk usage from exec node\nconst diskUsage = parseInt(msg.disk_usage) || baseMetrics.disk_usage || 0;\n\n// Get process count from exec node\nconst processCount = parseInt(msg.process_count) || 0;\n\n// Get TCP connection count from exec node\nconst tcpConnections = parseInt(msg.tcp_count) || 0;\n\n// Merge all metrics\nconst completeMetrics = {\n    ...baseMetrics,\n    disk_usage: diskUsage,\n    process_count: processCount,\n    tcp_connections: tcpConnections,\n    collected_at: new Date().toISOString()\n};\n\n// Store in context for historical comparison\nconst previousMetrics = context.get('previous_metrics');\nif (previousMetrics) {\n    completeMetrics.cpu_trend = completeMetrics.cpu_usage - previousMetrics.cpu_usage;\n    completeMetrics.memory_trend = completeMetrics.memory_usage - previousMetrics.memory_usage;\n    completeMetrics.tcp_trend = completeMetrics.tcp_connections - previousMetrics.tcp_connections;\n}\ncontext.set('previous_metrics', completeMetrics);\n\nmsg.payload = completeMetrics;\nreturn msg;",
    "outputs": 1
  },
  {
    "id": "store-postgres",
    "type": "function",
    "z": "metric-collector-flow",
    "name": "Prepare for PostgreSQL",
    "func": "// Prepare SQL insert statement for system_health table\nconst metrics = msg.payload;\n\nmsg.topic = `\nINSERT INTO system_health \n(cpu_usage, memory_usage, memory_total, disk_usage, disk_total, network_rx_bytes, network_tx_bytes, tcp_connections, process_count, load_average, timestamp)\nVALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, CURRENT_TIMESTAMP)\n`;\n\nmsg.payload = [\n    metrics.cpu_usage,\n    metrics.memory_usage,\n    metrics.memory_total,\n    metrics.disk_usage,\n    metrics.disk_total || 0,\n    metrics.network_rx_bytes,\n    metrics.network_tx_bytes,\n    metrics.tcp_connections,\n    metrics.process_count,\n    metrics.load_average\n];\n\nreturn msg;",
    "outputs": 1
  },
  {
    "id": "postgres-insert",
    "type": "postgresql",
    "z": "metric-collector-flow",
    "name": "Store in PostgreSQL",
    "query": "",
    "postgreSQLConfig": "",
    "split": false
  },
  {
    "id": "store-questdb",
    "type": "function",
    "z": "metric-collector-flow",
    "name": "Prepare for QuestDB",
    "func": "// Prepare data for QuestDB time-series storage\nconst metrics = msg.payload;\n\n// QuestDB insert format\nconst questdbData = {\n    table: 'system_metrics',\n    columns: {\n        cpu_usage: metrics.cpu_usage,\n        memory_usage: metrics.memory_usage,\n        memory_total: metrics.memory_total,\n        disk_usage: metrics.disk_usage,\n        network_rx_bytes: metrics.network_rx_bytes,\n        network_tx_bytes: metrics.network_tx_bytes,\n        tcp_connections: metrics.tcp_connections,\n        process_count: metrics.process_count,\n        load_avg: metrics.load_average[0] || 0,\n        hostname: metrics.hostname,\n        timestamp: new Date().toISOString()\n    }\n};\n\nmsg.payload = questdbData;\nmsg.questdb_query = `INSERT INTO system_metrics VALUES(\n    '${questdbData.columns.timestamp}',\n    ${questdbData.columns.cpu_usage},\n    ${questdbData.columns.memory_usage},\n    ${questdbData.columns.memory_total},\n    ${questdbData.columns.disk_usage},\n    ${questdbData.columns.network_rx_bytes},\n    ${questdbData.columns.network_tx_bytes},\n    ${questdbData.columns.tcp_connections},\n    ${questdbData.columns.process_count},\n    ${questdbData.columns.load_avg},\n    '${questdbData.columns.hostname}'\n);`;\n\nreturn msg;",
    "outputs": 1
  },
  {
    "id": "questdb-insert",
    "type": "http request",
    "z": "metric-collector-flow",
    "name": "Store in QuestDB",
    "method": "POST",
    "ret": "txt",
    "url": "http://localhost:${PORT_QUESTDB}/exec",
    "tls": "",
    "persist": false,
    "proxy": "",
    "followRedirects": true,
    "timeout": "10"
  },
  {
    "id": "cache-redis",
    "type": "function",
    "z": "metric-collector-flow",
    "name": "Cache Latest Metrics",
    "func": "// Cache the latest metrics in Redis for quick access\nconst metrics = msg.payload;\n\n// Create a summary for quick access\nconst summary = {\n    cpu: metrics.cpu_usage,\n    memory: metrics.memory_usage,\n    disk: metrics.disk_usage,\n    tcp: metrics.tcp_connections,\n    processes: metrics.process_count,\n    load: metrics.load_average[0] || 0,\n    updated: metrics.timestamp,\n    trends: {\n        cpu: metrics.cpu_trend || 0,\n        memory: metrics.memory_trend || 0,\n        tcp: metrics.tcp_trend || 0\n    }\n};\n\nmsg.topic = 'SET';\nmsg.payload = {\n    key: 'system_metrics:current',\n    value: JSON.stringify(summary),\n    ttl: 300 // 5 minutes TTL\n};\n\nreturn msg;",
    "outputs": 1
  },
  {
    "id": "redis-cache",
    "type": "redis-out",
    "z": "metric-collector-flow",
    "name": "Cache in Redis",
    "topic": "",
    "redis": "",
    "key": "",
    "value": ""
  },
  {
    "id": "performance-check",
    "type": "function",
    "z": "metric-collector-flow",
    "name": "Performance Health Check",
    "func": "// Perform quick performance health check\nconst metrics = msg.payload;\nconst alerts = [];\n\n// CPU check\nif (metrics.cpu_usage > 90) {\n    alerts.push({\n        type: 'cpu_critical',\n        severity: 'critical',\n        message: `CPU usage critical: ${metrics.cpu_usage}%`,\n        value: metrics.cpu_usage\n    });\n} else if (metrics.cpu_usage > 70) {\n    alerts.push({\n        type: 'cpu_warning',\n        severity: 'warning',\n        message: `CPU usage high: ${metrics.cpu_usage}%`,\n        value: metrics.cpu_usage\n    });\n}\n\n// Memory check\nif (metrics.memory_usage > 95) {\n    alerts.push({\n        type: 'memory_critical',\n        severity: 'critical',\n        message: `Memory usage critical: ${metrics.memory_usage}%`,\n        value: metrics.memory_usage\n    });\n} else if (metrics.memory_usage > 80) {\n    alerts.push({\n        type: 'memory_warning',\n        severity: 'warning',\n        message: `Memory usage high: ${metrics.memory_usage}%`,\n        value: metrics.memory_usage\n    });\n}\n\n// TCP connections check\nif (metrics.tcp_connections > 1000) {\n    alerts.push({\n        type: 'tcp_warning',\n        severity: 'warning',\n        message: `High TCP connections: ${metrics.tcp_connections}`,\n        value: metrics.tcp_connections\n    });\n}\n\n// Disk space check\nif (metrics.disk_usage > 95) {\n    alerts.push({\n        type: 'disk_critical',\n        severity: 'critical',\n        message: `Disk usage critical: ${metrics.disk_usage}%`,\n        value: metrics.disk_usage\n    });\n} else if (metrics.disk_usage > 80) {\n    alerts.push({\n        type: 'disk_warning',\n        severity: 'warning',\n        message: `Disk usage high: ${metrics.disk_usage}%`,\n        value: metrics.disk_usage\n    });\n}\n\nif (alerts.length > 0) {\n    msg.alerts = alerts;\n    msg.payload = {\n        timestamp: metrics.timestamp,\n        hostname: metrics.hostname,\n        alerts: alerts,\n        metrics_snapshot: metrics\n    };\n    return msg;\n}\n\nreturn null; // No alerts, don't continue",
    "outputs": 1
  },
  {
    "id": "alert-handler",
    "type": "function",
    "z": "metric-collector-flow",
    "name": "Handle Alerts",
    "func": "// Handle performance alerts\nconst data = msg.payload;\nconst alerts = data.alerts || [];\n\n// Group alerts by severity\nconst critical = alerts.filter(a => a.severity === 'critical');\nconst warnings = alerts.filter(a => a.severity === 'warning');\n\n// Prepare alert notification\nconst alertMessage = {\n    id: `alert_${Date.now()}`,\n    timestamp: data.timestamp,\n    hostname: data.hostname,\n    summary: {\n        total: alerts.length,\n        critical: critical.length,\n        warnings: warnings.length\n    },\n    alerts: alerts,\n    metrics: data.metrics_snapshot\n};\n\n// Store alert in Redis for processing\nmsg.topic = 'LPUSH';\nmsg.payload = {\n    key: 'system_alerts',\n    value: JSON.stringify(alertMessage)\n};\n\nreturn msg;",
    "outputs": 1
  },
  {
    "id": "redis-alerts",
    "type": "redis-out",
    "z": "metric-collector-flow",
    "name": "Queue Alerts",
    "topic": "",
    "redis": "",
    "key": "",
    "value": ""
  }
]
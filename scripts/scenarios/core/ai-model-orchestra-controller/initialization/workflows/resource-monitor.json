[
  {
    "id": "resource-monitor-timer",
    "type": "inject",
    "z": "resource-monitor-flow",
    "name": "Resource Monitor Timer",
    "props": [
      {
        "p": "payload"
      },
      {
        "p": "topic",
        "vt": "str"
      }
    ],
    "repeat": "5",
    "crontab": "",
    "once": true,
    "onceDelay": 0.1,
    "topic": "resource_check",
    "payload": "",
    "payloadType": "date",
    "x": 170,
    "y": 100,
    "wires": [["collect-system-resources"]]
  },
  {
    "id": "model-health-timer",
    "type": "inject",
    "z": "resource-monitor-flow",
    "name": "Model Health Timer",
    "props": [
      {
        "p": "payload"
      },
      {
        "p": "topic",
        "vt": "str"
      }
    ],
    "repeat": "30",
    "crontab": "",
    "once": true,
    "onceDelay": 5,
    "topic": "model_health_check",
    "payload": "",
    "payloadType": "date",
    "x": 170,
    "y": 200,
    "wires": [["check-ollama-health"]]
  },
  {
    "id": "collect-system-resources",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Collect System Resources",
    "func": "// Collect comprehensive system resource information\nconst fs = require('fs');\nconst os = require('os');\n\ntry {\n    // Memory information from /proc/meminfo\n    const memInfo = fs.readFileSync('/proc/meminfo', 'utf8');\n    const memTotal = parseInt(memInfo.match(/MemTotal:\\s+(\\d+)/)[1]) * 1024;\n    const memFree = parseInt(memInfo.match(/MemFree:\\s+(\\d+)/)[1]) * 1024;\n    const memAvailable = parseInt(memInfo.match(/MemAvailable:\\s+(\\d+)/)[1]) * 1024;\n    const buffers = parseInt(memInfo.match(/Buffers:\\s+(\\d+)/)[1]) * 1024;\n    const cached = parseInt(memInfo.match(/Cached:\\s+(\\d+)/)[1]) * 1024;\n    \n    // Swap information\n    const swapTotal = parseInt(memInfo.match(/SwapTotal:\\s+(\\d+)/)?.[1] || '0') * 1024;\n    const swapFree = parseInt(memInfo.match(/SwapFree:\\s+(\\d+)/)?.[1] || '0') * 1024;\n    const swapUsed = swapTotal - swapFree;\n    \n    // CPU load information\n    const loadAvg = fs.readFileSync('/proc/loadavg', 'utf8').trim().split(' ');\n    const cpuLoad1 = parseFloat(loadAvg[0]);\n    const cpuLoad5 = parseFloat(loadAvg[1]);\n    const cpuLoad15 = parseFloat(loadAvg[2]);\n    \n    // CPU count for load calculation\n    const cpuCount = os.cpus().length;\n    \n    // Disk usage for /tmp (where models might cache)\n    let diskUsage = {};\n    try {\n        const df = require('child_process').execSync('df -h /tmp').toString();\n        const diskLine = df.split('\\n')[1].split(/\\s+/);\n        diskUsage = {\n            filesystem: diskLine[0],\n            size: diskLine[1],\n            used: diskLine[2],\n            available: diskLine[3],\n            use_percent: parseInt(diskLine[4])\n        };\n    } catch (e) {\n        diskUsage = { error: 'Could not get disk usage' };\n    }\n    \n    // Calculate memory pressure\n    const memoryPressure = 1 - (memAvailable / memTotal);\n    \n    // Determine memory pressure level\n    let pressureLevel = 'low';\n    if (memoryPressure > 0.9) pressureLevel = 'critical';\n    else if (memoryPressure > 0.7) pressureLevel = 'high';\n    else if (memoryPressure > 0.3) pressureLevel = 'moderate';\n    \n    // CPU usage estimation (rough)\n    const cpuUsagePercent = Math.min((cpuLoad1 / cpuCount) * 100, 100);\n    \n    msg.payload = {\n        timestamp: new Date().toISOString(),\n        memory: {\n            total: memTotal,\n            free: memFree,\n            available: memAvailable,\n            buffers: buffers,\n            cached: cached,\n            used: memTotal - memAvailable,\n            total_gb: memTotal / 1024 / 1024 / 1024,\n            free_gb: memFree / 1024 / 1024 / 1024,\n            available_gb: memAvailable / 1024 / 1024 / 1024,\n            used_gb: (memTotal - memAvailable) / 1024 / 1024 / 1024,\n            usage_percent: ((memTotal - memAvailable) / memTotal) * 100\n        },\n        swap: {\n            total: swapTotal,\n            free: swapFree,\n            used: swapUsed,\n            total_gb: swapTotal / 1024 / 1024 / 1024,\n            used_gb: swapUsed / 1024 / 1024 / 1024,\n            usage_percent: swapTotal > 0 ? (swapUsed / swapTotal) * 100 : 0\n        },\n        cpu: {\n            load_1min: cpuLoad1,\n            load_5min: cpuLoad5,\n            load_15min: cpuLoad15,\n            core_count: cpuCount,\n            usage_percent: cpuUsagePercent\n        },\n        disk: diskUsage,\n        pressure: {\n            memory_pressure: memoryPressure,\n            pressure_level: pressureLevel,\n            cpu_pressure: cpuLoad1 / cpuCount\n        },\n        system: {\n            uptime: os.uptime(),\n            hostname: os.hostname(),\n            platform: os.platform(),\n            arch: os.arch()\n        }\n    };\n    \n    return msg;\n    \n} catch (error) {\n    msg.payload = {\n        error: 'Failed to collect system resources',\n        details: error.message,\n        timestamp: new Date().toISOString()\n    };\n    return msg;\n}",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 420,
    "y": 100,
    "wires": [["publish-resource-metrics", "store-resource-metrics", "check-resource-alerts"]]
  },
  {
    "id": "check-ollama-health",
    "type": "http request",
    "z": "resource-monitor-flow",
    "name": "Check Ollama Health",
    "method": "GET",
    "ret": "obj",
    "paytoqs": "ignore",
    "url": "http://localhost:11434/api/tags",
    "tls": "",
    "persist": false,
    "proxy": "",
    "authType": "",
    "senderr": false,
    "timeout": 10,
    "x": 420,
    "y": 200,
    "wires": [["process-model-health"], ["handle-model-health-error"]]
  },
  {
    "id": "process-model-health",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Process Model Health",
    "func": "// Process Ollama model health and calculate model metrics\nconst ollamaResponse = msg.payload;\nconst timestamp = new Date().toISOString();\n\nlet modelHealth = {\n    timestamp: timestamp,\n    service_healthy: true,\n    models: {},\n    total_models: 0,\n    healthy_models: 0,\n    total_size_gb: 0\n};\n\nif (ollamaResponse && ollamaResponse.models) {\n    modelHealth.total_models = ollamaResponse.models.length;\n    \n    ollamaResponse.models.forEach(model => {\n        const sizeGb = model.size ? model.size / (1024 * 1024 * 1024) : 0;\n        \n        modelHealth.models[model.name] = {\n            name: model.name,\n            size_bytes: model.size || 0,\n            size_gb: sizeGb,\n            modified: model.modified,\n            digest: model.digest,\n            healthy: true,\n            last_check: timestamp,\n            family: model.details?.family || 'unknown'\n        };\n        \n        modelHealth.healthy_models++;\n        modelHealth.total_size_gb += sizeGb;\n    });\n} else {\n    modelHealth.service_healthy = false;\n    modelHealth.error = 'No models response from Ollama';\n}\n\nmsg.payload = modelHealth;\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 680,
    "y": 200,
    "wires": [["publish-model-health", "store-model-health", "check-model-alerts"]]
  },
  {
    "id": "handle-model-health-error",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Handle Model Health Error",
    "func": "// Handle Ollama health check errors\nconst error = msg.payload;\n\nmsg.payload = {\n    timestamp: new Date().toISOString(),\n    service_healthy: false,\n    models: {},\n    total_models: 0,\n    healthy_models: 0,\n    total_size_gb: 0,\n    error: error.message || 'Ollama service unavailable',\n    status_code: msg.statusCode\n};\n\nnode.warn('Ollama health check failed: ' + (error.message || 'Unknown error'));\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 680,
    "y": 260,
    "wires": [["publish-model-health", "store-model-health", "check-model-alerts"]]
  },
  {
    "id": "publish-resource-metrics",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Publish Resource Metrics",
    "func": "// Publish resource metrics to Redis for real-time monitoring\nconst resourceEvent = {\n    type: 'resource_metrics',\n    source: 'ai-orchestrator',\n    ...msg.payload\n};\n\n// Store in global context for other flows to access\ncontext.global.set('systemResources', msg.payload);\n\n// Prepare for Redis publishing\nmsg.topic = 'orchestrator:resources';\nmsg.payload = resourceEvent;\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 720,
    "y": 80,
    "wires": [["redis-publish"]]
  },
  {
    "id": "publish-model-health",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Publish Model Health",
    "func": "// Publish model health to Redis for real-time monitoring\nconst healthEvent = {\n    type: 'model_health',\n    source: 'ai-orchestrator',\n    ...msg.payload\n};\n\n// Store in global context for other flows to access\ncontext.global.set('modelHealth', msg.payload);\n\n// Prepare for Redis publishing\nmsg.topic = 'orchestrator:model_health';\nmsg.payload = healthEvent;\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 940,
    "y": 180,
    "wires": [["redis-publish"]]
  },
  {
    "id": "store-resource-metrics",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Store Resource Metrics",
    "func": "// Prepare data for PostgreSQL storage\nconst resources = msg.payload;\n\nif (resources.error) {\n    // Don't store error data\n    return null;\n}\n\n// Prepare SQL insert\nmsg.topic = 'INSERT INTO system_resources (memory_available_gb, memory_free_gb, memory_total_gb, memory_used_gb, memory_usage_percent, cpu_usage_percent, cpu_load_1min, swap_used_percent, disk_usage_percent, memory_pressure, pressure_level) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)';\n\nmsg.payload = [\n    resources.memory.available_gb,\n    resources.memory.free_gb,\n    resources.memory.total_gb,\n    resources.memory.used_gb,\n    resources.memory.usage_percent,\n    resources.cpu.usage_percent,\n    resources.cpu.load_1min,\n    resources.swap.usage_percent,\n    resources.disk.use_percent || 0,\n    resources.pressure.memory_pressure,\n    resources.pressure.pressure_level\n];\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 720,
    "y": 120,
    "wires": [["postgres-store"]]
  },
  {
    "id": "store-model-health",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Store Model Health",
    "func": "// Store model health metrics in PostgreSQL\nconst health = msg.payload;\n\nif (!health.service_healthy) {\n    // Log service health issue but don't store individual model data\n    node.warn('Ollama service unhealthy: ' + (health.error || 'Unknown error'));\n    return null;\n}\n\n// Prepare batch insert for all models\nconst modelUpdates = [];\n\nObject.values(health.models).forEach(model => {\n    modelUpdates.push({\n        topic: 'INSERT INTO model_metrics (model_name, size_gb, last_health_check, healthy) VALUES ($1, $2, $3, $4) ON CONFLICT (model_name) DO UPDATE SET size_gb = $2, last_health_check = $3, healthy = $4',\n        payload: [model.name, model.size_gb, model.last_check, model.healthy]\n    });\n});\n\n// Store all model updates in context for batch processing\ncontext.set('modelUpdates', modelUpdates);\n\n// Return first update to trigger storage\nif (modelUpdates.length > 0) {\n    msg.topic = modelUpdates[0].topic;\n    msg.payload = modelUpdates[0].payload;\n    return msg;\n}\n\nreturn null;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 940,
    "y": 220,
    "wires": [["postgres-store"]]
  },
  {
    "id": "check-resource-alerts",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Check Resource Alerts",
    "func": "// Check for resource alert conditions\nconst resources = msg.payload;\n\nif (resources.error) {\n    return null;\n}\n\nconst alerts = [];\n\n// Memory pressure alerts\nif (resources.pressure.memory_pressure > 0.9) {\n    alerts.push({\n        type: 'critical',\n        category: 'memory',\n        message: `Critical memory pressure: ${(resources.pressure.memory_pressure * 100).toFixed(1)}%`,\n        value: resources.pressure.memory_pressure,\n        threshold: 0.9\n    });\n} else if (resources.pressure.memory_pressure > 0.7) {\n    alerts.push({\n        type: 'warning',\n        category: 'memory',\n        message: `High memory pressure: ${(resources.pressure.memory_pressure * 100).toFixed(1)}%`,\n        value: resources.pressure.memory_pressure,\n        threshold: 0.7\n    });\n}\n\n// CPU load alerts\nif (resources.cpu.usage_percent > 90) {\n    alerts.push({\n        type: 'warning',\n        category: 'cpu',\n        message: `High CPU usage: ${resources.cpu.usage_percent.toFixed(1)}%`,\n        value: resources.cpu.usage_percent,\n        threshold: 90\n    });\n}\n\n// Swap usage alerts\nif (resources.swap.usage_percent > 50) {\n    alerts.push({\n        type: 'warning',\n        category: 'swap',\n        message: `High swap usage: ${resources.swap.usage_percent.toFixed(1)}%`,\n        value: resources.swap.usage_percent,\n        threshold: 50\n    });\n}\n\n// Disk usage alerts\nif (resources.disk.use_percent && resources.disk.use_percent > 90) {\n    alerts.push({\n        type: 'warning',\n        category: 'disk',\n        message: `High disk usage: ${resources.disk.use_percent}%`,\n        value: resources.disk.use_percent,\n        threshold: 90\n    });\n}\n\nif (alerts.length > 0) {\n    msg.payload = {\n        timestamp: resources.timestamp,\n        alerts: alerts,\n        system_status: 'degraded'\n    };\n    return msg;\n}\n\nreturn null; // No alerts",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 720,
    "y": 160,
    "wires": [["alert-handler"]]
  },
  {
    "id": "check-model-alerts",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Check Model Alerts",
    "func": "// Check for model health alert conditions\nconst health = msg.payload;\nconst alerts = [];\n\n// Service health alert\nif (!health.service_healthy) {\n    alerts.push({\n        type: 'critical',\n        category: 'model_service',\n        message: 'Ollama service is unavailable',\n        error: health.error\n    });\n}\n\n// No models available alert\nif (health.healthy_models === 0) {\n    alerts.push({\n        type: 'critical',\n        category: 'models',\n        message: 'No healthy models available',\n        total_models: health.total_models\n    });\n}\n\n// Low model availability alert\nif (health.total_models > 0 && health.healthy_models < health.total_models) {\n    alerts.push({\n        type: 'warning',\n        category: 'models',\n        message: `${health.total_models - health.healthy_models} models are unhealthy`,\n        healthy_models: health.healthy_models,\n        total_models: health.total_models\n    });\n}\n\n// Large model size alert (potential memory pressure)\nif (health.total_size_gb > 20) {\n    alerts.push({\n        type: 'info',\n        category: 'model_size',\n        message: `Large total model size: ${health.total_size_gb.toFixed(1)}GB`,\n        total_size_gb: health.total_size_gb\n    });\n}\n\nif (alerts.length > 0) {\n    msg.payload = {\n        timestamp: health.timestamp,\n        alerts: alerts,\n        model_status: health.service_healthy ? 'degraded' : 'critical'\n    };\n    return msg;\n}\n\nreturn null; // No alerts",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 940,
    "y": 260,
    "wires": [["alert-handler"]]
  },
  {
    "id": "alert-handler",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Alert Handler",
    "func": "// Handle system alerts\nconst alertData = msg.payload;\n\n// Log alerts to console\nalertData.alerts.forEach(alert => {\n    const logLevel = alert.type === 'critical' ? 'error' : alert.type === 'warning' ? 'warn' : 'log';\n    node[logLevel](`[${alert.type.toUpperCase()}] ${alert.category}: ${alert.message}`);\n});\n\n// Prepare alert for publishing\nmsg.topic = 'orchestrator:alerts';\nmsg.payload = {\n    type: 'system_alert',\n    source: 'ai-orchestrator',\n    ...alertData\n};\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 1140,
    "y": 210,
    "wires": [["redis-publish"]]
  },
  {
    "id": "redis-publish",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "Redis Publish Placeholder",
    "func": "// Placeholder for Redis publishing\n// In a real implementation, this would use a Redis node\n// For now, just log the event that would be published\n\nnode.log(`[REDIS PUBLISH] Topic: ${msg.topic}`);\nnode.log(`[REDIS PUBLISH] Payload: ${JSON.stringify(msg.payload, null, 2)}`);\n\n// Store in global context for testing\ncontext.global.set('lastRedisEvent', {\n    topic: msg.topic,\n    payload: msg.payload,\n    timestamp: new Date().toISOString()\n});\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 1360,
    "y": 150,
    "wires": [[]]
  },
  {
    "id": "postgres-store",
    "type": "function",
    "z": "resource-monitor-flow",
    "name": "PostgreSQL Store Placeholder",
    "func": "// Placeholder for PostgreSQL storage\n// In a real implementation, this would use a PostgreSQL node\n// For now, just log the query that would be executed\n\nif (msg.topic && msg.payload) {\n    node.log(`[POSTGRES STORE] Query: ${msg.topic}`);\n    node.log(`[POSTGRES STORE] Params: ${JSON.stringify(msg.payload)}`);\n    \n    // Store in global context for testing\n    context.global.set('lastDbQuery', {\n        query: msg.topic,\n        params: msg.payload,\n        timestamp: new Date().toISOString()\n    });\n}\n\nreturn msg;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 1360,
    "y": 100,
    "wires": [[]]
  },
  {
    "id": "resource-monitor-flow",
    "type": "tab",
    "label": "Resource Monitor",
    "disabled": false,
    "info": "Continuous monitoring of system resources and AI model health\\n\\nFeatures:\\n- System resource monitoring (CPU, memory, disk, swap)\\n- Memory pressure calculation and alerting\\n- Ollama model health checking\\n- Real-time metrics publishing via Redis\\n- Historical data storage in PostgreSQL\\n- Automated alert generation\\n\\nMonitoring Intervals:\\n- System resources: Every 5 seconds\\n- Model health: Every 30 seconds\\n\\nAlert Conditions:\\n- Memory pressure > 70% (warning), > 90% (critical)\\n- CPU usage > 90% (warning)\\n- Swap usage > 50% (warning)\\n- Disk usage > 90% (warning)\\n- Ollama service unavailable (critical)\\n- No healthy models available (critical)"
  }
]
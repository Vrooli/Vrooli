{
  "name": "Audio Intelligence Pipeline",
  "nodes": [
    {
      "parameters": {
        "path": "transcription-upload",
        "responseMode": "responseNode",
        "options": {
          "allowedOrigins": "*",
          "httpMethod": "POST"
        }
      },
      "id": "webhook-file-upload",
      "name": "File Upload Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [240, 300],
      "webhookId": "transcription-upload"
    },
    
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Validate and process uploaded file\nconst inputData = $input.first().json;\n\n// Validate required fields\nif (!inputData.filename || !inputData.fileData) {\n  throw new Error('Missing required fields: filename and fileData');\n}\n\n// Validate file format\nconst supportedFormats = ['mp3', 'wav', 'm4a', 'ogg', 'flac', 'mp4'];\nconst fileExtension = inputData.filename.split('.').pop().toLowerCase();\nif (!supportedFormats.includes(fileExtension)) {\n  throw new Error(`Unsupported file format: ${fileExtension}. Supported formats: ${supportedFormats.join(', ')}`);\n}\n\n// Generate unique paths and IDs\nconst transcriptionId = crypto.randomUUID();\nconst sessionId = inputData.sessionId || 'anonymous-session';\nconst timestamp = new Date().toISOString();\nconst audioPath = `audio-files/${transcriptionId}-${inputData.filename}`;\nconst transcriptPath = `transcriptions/${transcriptionId}-transcript.txt`;\n\n// Process file metadata\nconst processedData = {\n  // Transcription record fields\n  transcriptionId: transcriptionId,\n  filename: inputData.filename,\n  originalFilePath: inputData.originalPath || `/uploads/${inputData.filename}`,\n  contentType: inputData.contentType || 'audio/mpeg',\n  fileSizeBytes: inputData.fileSizeBytes || 0,\n  sessionId: sessionId,\n  userIdentifier: inputData.userIdentifier || 'anonymous',\n  \n  // Storage paths\n  minioAudioPath: audioPath,\n  minioTranscriptPath: transcriptPath,\n  \n  // File data for processing\n  fileData: inputData.fileData,\n  \n  // Processing metadata\n  status: 'processing',\n  embeddingStatus: 'pending',\n  whisperModel: inputData.whisperModel || 'base',\n  processingStartTime: Date.now(),\n  createdAt: timestamp\n};\n\nreturn processedData;"
      },
      "id": "process-file-input",
      "name": "Process File Input",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 300]
    },
    
    {
      "parameters": {
        "url": "http://localhost:9000",
        "sendBody": true,
        "bodyContentType": "multipart-form-data",
        "bodyParameters": {
          "parameters": [
            {
              "name": "bucket",
              "value": "audio-files"
            },
            {
              "name": "key",
              "value": "={{ $json.minioAudioPath }}"
            },
            {
              "name": "file",
              "value": "={{ $json.fileData }}"
            }
          ]
        },
        "options": {
          "timeout": 60000
        }
      },
      "id": "store-audio-file",
      "name": "Store Audio File (MinIO)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [680, 200]
    },
    
    {
      "parameters": {
        "url": "http://localhost:8090/transcribe",
        "sendBody": true,
        "bodyContentType": "multipart-form-data",
        "bodyParameters": {
          "parameters": [
            {
              "name": "audio",
              "value": "={{ $json.fileData }}"
            },
            {
              "name": "model",
              "value": "={{ $json.whisperModel }}"
            },
            {
              "name": "response_format",
              "value": "json"
            },
            {
              "name": "word_timestamps",
              "value": "true"
            }
          ]
        },
        "options": {
          "timeout": 300000
        }
      },
      "id": "transcribe-audio",
      "name": "Transcribe Audio (Whisper)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [680, 400]
    },
    
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Process transcription results and prepare for database storage\nconst transcriptionResult = $input.first().json;\nconst fileData = $input.all()[0].json;\n\n// Extract transcription data from Whisper response\nconst whisperResponse = transcriptionResult.body || transcriptionResult;\nconst transcriptionText = whisperResponse.text || '';\nconst wordTimestamps = whisperResponse.words || [];\nconst language = whisperResponse.language || 'en';\n\n// Calculate processing metrics\nconst processingEndTime = Date.now();\nconst processingTime = processingEndTime - fileData.processingStartTime;\n\n// Prepare database record\nconst dbRecord = {\n  id: fileData.transcriptionId,\n  filename: fileData.filename,\n  original_file_path: fileData.originalFilePath,\n  file_size_bytes: fileData.fileSizeBytes,\n  content_type: fileData.contentType,\n  duration_seconds: whisperResponse.duration || null,\n  \n  transcription_text: transcriptionText,\n  word_timestamps: JSON.stringify(wordTimestamps),\n  confidence_score: whisperResponse.confidence || 0.95,\n  language_detected: language,\n  \n  whisper_model_used: fileData.whisperModel,\n  processing_time_ms: processingTime,\n  status: 'completed',\n  embedding_status: 'pending',\n  \n  minio_audio_path: fileData.minioAudioPath,\n  minio_transcript_path: fileData.minioTranscriptPath,\n  \n  session_id: fileData.sessionId,\n  user_identifier: fileData.userIdentifier,\n  created_at: fileData.createdAt,\n  updated_at: new Date().toISOString()\n};\n\n// Also prepare data for embedding generation\nconst embeddingData = {\n  transcriptionId: fileData.transcriptionId,\n  text: transcriptionText,\n  model: 'nomic-embed-text'\n};\n\nreturn {\n  dbRecord: dbRecord,\n  embeddingData: embeddingData,\n  transcriptionText: transcriptionText\n};"
      },
      "id": "process-transcription",
      "name": "Process Transcription Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [900, 400]
    },
    
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO audio_intelligence_platform.transcriptions (id, filename, original_file_path, file_size_bytes, content_type, duration_seconds, transcription_text, word_timestamps, confidence_score, language_detected, whisper_model_used, processing_time_ms, status, embedding_status, minio_audio_path, minio_transcript_path, session_id, user_identifier, created_at, updated_at) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20) RETURNING id",
        "additionalFields": {
          "mode": "independently"
        }
      },
      "id": "store-transcription",
      "name": "Store Transcription (PostgreSQL)",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [1120, 300],
      "credentials": {
        "postgres": {
          "id": "postgres-audio-intelligence",
          "name": "PostgreSQL - Audio Intelligence"
        }
      }
    },
    
    {
      "parameters": {
        "url": "http://localhost:11434/api/embeddings",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "nomic-embed-text"
            },
            {
              "name": "prompt",
              "value": "={{ $json.embeddingData.text }}"
            }
          ]
        },
        "options": {
          "timeout": 30000
        }
      },
      "id": "generate-embeddings",
      "name": "Generate Embeddings (Ollama)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1120, 500]
    },
    
    {
      "parameters": {
        "url": "http://localhost:6333/collections/transcription-embeddings/points",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "points",
              "value": "=[{\"id\": \"{{ $json.embeddingData.transcriptionId }}\", \"vector\": {{ $('Generate Embeddings (Ollama)').item.json.embedding }}, \"payload\": {\"transcription_id\": \"{{ $json.embeddingData.transcriptionId }}\", \"text\": \"{{ $json.transcriptionText.substring(0, 1000) }}\", \"filename\": \"{{ $json.dbRecord.filename }}\", \"created_at\": \"{{ $json.dbRecord.created_at }}\"}}]"
            }
          ]
        },
        "options": {
          "timeout": 30000
        }
      },
      "id": "store-embeddings",
      "name": "Store Embeddings (Qdrant)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1340, 500]
    },
    
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE audio_intelligence_platform.transcriptions SET embedding_status = 'completed', updated_at = NOW() WHERE id = $1",
        "additionalFields": {
          "mode": "independently"
        }
      },
      "id": "update-embedding-status",
      "name": "Update Embedding Status",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [1560, 400],
      "credentials": {
        "postgres": {
          "id": "postgres-audio-intelligence",
          "name": "PostgreSQL - Audio Intelligence"
        }
      }
    },
    
    {
      "parameters": {
        "url": "http://localhost:9000",
        "sendBody": true,
        "bodyContentType": "text/plain",
        "bodyParameters": {
          "parameters": [
            {
              "name": "bucket",
              "value": "transcriptions"
            },
            {
              "name": "key",
              "value": "={{ $json.dbRecord.minio_transcript_path }}"
            },
            {
              "name": "content",
              "value": "={{ $json.transcriptionText }}"
            }
          ]
        },
        "options": {
          "timeout": 30000
        }
      },
      "id": "store-transcript-file",
      "name": "Store Transcript File (MinIO)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1340, 300]
    },
    
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Build final response for the upload request\nconst dbResult = $input.all().find(item => item.json.id);\nconst processingData = $input.all().find(item => item.json.dbRecord);\n\nconst response = {\n  success: true,\n  message: 'Transcription completed successfully',\n  transcriptionId: processingData.json.dbRecord.id,\n  filename: processingData.json.dbRecord.filename,\n  transcriptionText: processingData.json.transcriptionText,\n  confidence: processingData.json.dbRecord.confidence_score,\n  language: processingData.json.dbRecord.language_detected,\n  duration: processingData.json.dbRecord.duration_seconds,\n  processingTime: processingData.json.dbRecord.processing_time_ms,\n  status: 'completed',\n  embeddingStatus: 'completed',\n  createdAt: processingData.json.dbRecord.created_at,\n  \n  // URLs for accessing the transcription\n  urls: {\n    view: `http://localhost:5681/transcription/${processingData.json.dbRecord.id}`,\n    download: `http://localhost:9000/transcriptions/${processingData.json.dbRecord.minio_transcript_path}`,\n    audio: `http://localhost:9000/audio-files/${processingData.json.dbRecord.minio_audio_path}`\n  }\n};\n\nreturn response;"
      },
      "id": "build-response",
      "name": "Build Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1780, 400]
    },
    
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Content-Type",
                "value": "application/json"
              }
            ]
          }
        }
      },
      "id": "response-node",
      "name": "Success Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [2000, 400]
    }
  ],
  
  "connections": {
    "File Upload Webhook": {
      "main": [
        [
          {
            "node": "Process File Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    
    "Process File Input": {
      "main": [
        [
          {
            "node": "Store Audio File (MinIO)",
            "type": "main",
            "index": 0
          },
          {
            "node": "Transcribe Audio (Whisper)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    
    "Transcribe Audio (Whisper)": {
      "main": [
        [
          {
            "node": "Process Transcription Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    
    "Process Transcription Results": {
      "main": [
        [
          {
            "node": "Store Transcription (PostgreSQL)",
            "type": "main",
            "index": 0
          },
          {
            "node": "Generate Embeddings (Ollama)",
            "type": "main",
            "index": 0
          },
          {
            "node": "Store Transcript File (MinIO)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    
    "Generate Embeddings (Ollama)": {
      "main": [
        [
          {
            "node": "Store Embeddings (Qdrant)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    
    "Store Embeddings (Qdrant)": {
      "main": [
        [
          {
            "node": "Update Embedding Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    
    "Update Embedding Status": {
      "main": [
        [
          {
            "node": "Build Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    
    "Store Transcription (PostgreSQL)": {
      "main": [
        [
          {
            "node": "Build Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    
    "Store Transcript File (MinIO)": {
      "main": [
        [
          {
            "node": "Build Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    
    "Build Response": {
      "main": [
        [
          {
            "node": "Success Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  
  "active": true,
  "settings": {
    "executionOrder": "v1",
    "saveManualExecutions": true,
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": {
      "id": "error-handler-workflow"
    }
  },
  
  "versionId": "transcription-pipeline-v1",
  "id": "transcription-pipeline",
  
  "meta": {
    "templateCreatedBy": "audio-intelligence-platform",
    "instanceId": "audio-intelligence-pipeline"
  },
  
  "tags": [
    {
      "id": "audio-intelligence",
      "name": "Audio Intelligence"
    },
    {
      "id": "audio-processing",
      "name": "Audio Processing"
    },
    {
      "id": "ai-workflow",
      "name": "AI Workflow"
    }
  ]
}
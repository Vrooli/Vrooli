name: document-manager
description: Comprehensive test suite for AI-powered documentation management SaaS platform
version: 2.0.0

metadata:
  category: productivity
  tags: [documentation, ai, automation, saas, testing]
  author: Vrooli Core Team
  estimated_runtime: "15-25 minutes"
  
setup:
  - name: Initialize database schema
    type: postgres
    action: execute_schema
    file: initialization/storage/postgres/schema.sql
    timeout: 60
  
  - name: Load seed data
    type: postgres
    action: execute_sql
    file: initialization/storage/postgres/seed.sql
    timeout: 30
  
  - name: Create Qdrant collections
    type: qdrant
    action: create_collections
    config_file: initialization/storage/qdrant/collections.json
    timeout: 30
  
  - name: Deploy n8n workflows
    type: n8n
    action: import_workflows
    files:
      - initialization/automation/n8n/doc-monitor-workflow.json
      - initialization/automation/n8n/improvement-processor.json
      - initialization/automation/n8n/notification-router.json
    timeout: 120
  
  - name: Deploy Windmill application
    type: windmill
    action: deploy_app
    file: initialization/automation/windmill/app.json
    flows_dir: initialization/automation/windmill/flows
    timeout: 180
  
  - name: Load configuration files
    type: configuration
    action: load_configs
    files:
      - initialization/configuration/agent-presets.json
      - initialization/configuration/resource-urls.json
      - initialization/configuration/notification-rules.json
    timeout: 30

tests:
  # Resource Integration Tests
  - name: Resource connectivity
    description: Verify all required resources are accessible and functional
    category: infrastructure
    timeout: 300
    steps:
      - action: check_resource_health
        resource: postgres
        expected: healthy
      - action: check_resource_health
        resource: redis
        expected: healthy
      - action: check_resource_health
        resource: qdrant
        expected: healthy
      - action: check_resource_health
        resource: ollama
        expected: healthy
      - action: check_resource_health
        resource: n8n
        expected: healthy
      - action: check_resource_health
        resource: windmill
        expected: healthy
      - action: check_resource_health
        resource: unstructured_io
        expected: healthy

  # Database Schema Tests  
  - name: Database schema validation
    description: Verify database schema is properly created with all tables and relationships
    category: database
    timeout: 60
    steps:
      - action: verify_table_exists
        table: applications
        columns: [id, name, repository_url, health_score, notification_settings]
      - action: verify_table_exists
        table: agents
        columns: [id, name, type, application_id, auto_apply_threshold, last_performance_score]
      - action: verify_table_exists
        table: improvement_queue
        columns: [id, agent_id, type, severity, status, user_feedback, applied_result]
      - action: verify_table_exists
        table: agent_templates
        columns: [id, name, type, default_config, is_system_template]
      - action: verify_table_exists
        table: improvement_feedback
        columns: [id, improvement_id, feedback_type, effectiveness_rating]
      - action: verify_table_exists
        table: notification_preferences
        columns: [id, user_id, application_id, channel, severity_threshold]
      - action: verify_table_exists
        table: audit_log
        columns: [id, entity_type, entity_id, action, performed_by]
      - action: verify_foreign_keys
        relationships:
          - agents.application_id -> applications.id
          - improvement_queue.agent_id -> agents.id
          - improvement_feedback.improvement_id -> improvement_queue.id

  # Application Management Tests
  - name: Application CRUD operations
    description: Test complete application lifecycle management
    category: application_management
    timeout: 120
    steps:
      - action: create_application
        name: "Test Documentation Project"
        repository_url: "https://github.com/test/test-docs"
        documentation_path: "/docs"
        expected_status: success
      - action: verify_application_created
        name: "Test Documentation Project"
        assert: exists
      - action: update_application
        name: "Test Documentation Project"
        new_name: "Updated Test Project"
        expected_status: success
      - action: get_application_summary
        name: "Updated Test Project"
        assert: [name_updated, statistics_available]
      - action: trigger_application_scan
        name: "Updated Test Project" 
        expected_status: success

  # Agent Management Tests
  - name: Agent lifecycle management
    description: Test agent creation, configuration, and execution
    category: agent_management
    timeout: 300
    steps:
      - action: create_agent_from_preset
        application: "Updated Test Project"
        preset: drift_detector
        name: "Test Drift Detector"
        expected_status: success
      - action: create_agent_from_preset
        application: "Updated Test Project"
        preset: link_validator
        name: "Test Link Validator"
        expected_status: success
      - action: verify_agent_exists
        name: "Test Drift Detector"
        assert: [enabled, scheduled]
      - action: update_agent_config
        name: "Test Drift Detector"
        config:
          drift_threshold: 0.25
          semantic_analysis: true
        expected_status: success
      - action: get_agent_performance_metrics
        name: "Test Drift Detector"
        days: 7
        assert: metrics_available

  # Improvement Queue Tests
  - name: Improvement queue workflow
    description: Test complete improvement suggestion and approval workflow
    category: improvement_processing
    timeout: 240
    steps:
      - action: simulate_agent_analysis
        agent: "Test Link Validator"
        mock_findings:
          - type: broken_link
            severity: high
            title: "404 Error on deployment guide link"
            suggested_fix:
              old_url: "https://example.com/deploy/guide"
              new_url: "https://example.com/deployment/guide"
              confidence: 0.95
      - action: verify_improvement_queued
        assert: [status_pending, severity_high]
      - action: approve_improvement
        improvement_id: latest
        reviewed_by: "test_user"
        review_notes: "Link fix looks correct"
        expected_status: success
      - action: verify_improvement_status
        improvement_id: latest
        expected_status: approved
      - action: simulate_improvement_application
        improvement_id: latest
        expected_result: success
      - action: add_improvement_feedback
        improvement_id: latest
        feedback_type: positive
        effectiveness_rating: 5
        feedback_text: "Fix resolved the issue completely"
        created_by: "test_user"

  # Batch Processing Tests
  - name: Batch improvement processing
    description: Test batch operations on multiple improvements
    category: batch_processing
    timeout: 180
    steps:
      - action: create_multiple_improvements
        count: 5
        types: [broken_link, outdated_content, missing_documentation]
        severities: [medium, low, medium, high, low]
      - action: batch_approve_improvements
        filter:
          severity: [medium, low]
        reviewed_by: "batch_processor"
        expected_count: 4
      - action: verify_batch_results
        assert: [approved_count_4, pending_count_1]
      - action: get_queue_statistics
        assert: [status_distribution, severity_distribution]

  # Notification System Tests
  - name: Notification routing and delivery
    description: Test smart notification system with multiple channels
    category: notifications
    timeout: 120
    steps:
      - action: configure_test_notifications
        channels: [ui, webhook]
        severity_threshold: medium
      - action: trigger_notification
        type: improvement_suggestion
        severity: high
        data:
          title: "Critical documentation issue detected"
          application: "Updated Test Project"
      - action: verify_notification_delivered
        channels: [ui, webhook]
        assert: delivered
      - action: test_notification_batching
        create_count: 3
        severity: low
        assert: batched_delivery

  # AI Model Integration Tests
  - name: AI model integration
    description: Test Ollama integration for documentation analysis
    category: ai_integration
    timeout: 300
    steps:
      - action: verify_ollama_models
        required_models: [llama3.2, nomic-embed-text]
        assert: models_available
      - action: test_document_analysis
        sample_text: "This is a sample documentation section about API endpoints."
        expected_analysis: structured_response
      - action: test_embedding_generation
        text: "Documentation quality analysis"
        expected_dimensions: 768
      - action: verify_qdrant_storage
        collection: documentation_embeddings
        assert: vectors_stored

  # UI Application Tests
  - name: Windmill dashboard functionality
    description: Test main dashboard UI application and interactions
    category: ui_testing
    timeout: 180
    steps:
      - action: access_dashboard
        url: "http://localhost:5681"
        expected_status: 200
      - action: verify_dashboard_components
        components: [applications_grid, agents_grid, queue_grid]
        assert: components_rendered
      - action: test_application_creation_form
        form_data:
          name: "UI Test Application"
          repository_url: "https://github.com/test/ui-test"
        expected_result: success
      - action: test_agent_configuration_ui
        application: "UI Test Application"
        agent_type: coverage_checker
        expected_result: agent_created
      - action: test_queue_management_ui
        actions: [approve, deny, request_revision]
        assert: actions_functional

  # Performance and Scalability Tests
  - name: System performance validation
    description: Test system performance under load
    category: performance
    timeout: 300
    steps:
      - action: create_load_test_data
        applications: 10
        agents_per_app: 3
        improvements: 50
      - action: measure_dashboard_load_time
        assert: less_than_5_seconds
      - action: measure_database_query_performance
        queries: [list_applications, list_agents, list_queue_items]
        assert: less_than_1_second_each
      - action: test_concurrent_agent_execution
        concurrent_agents: 5
        assert: no_conflicts

  # Integration Workflow Tests
  - name: End-to-end workflow integration
    description: Test complete workflow from setup to improvement application
    category: integration
    timeout: 600
    steps:
      - action: setup_complete_workflow
        application_name: "E2E Test Project"
        repository_url: "https://github.com/test/e2e-docs"
        agent_types: [drift_detector, link_validator, coverage_checker]
      - action: simulate_documentation_changes
        changes:
          - type: broken_link
            location: "README.md"
          - type: outdated_api
            location: "api/authentication.md"
          - type: missing_examples
            location: "tutorials/getting-started.md"
      - action: trigger_full_analysis
        application: "E2E Test Project"
        expected_improvements: 3
      - action: process_improvement_workflow
        steps: [review, approve, apply, feedback]
        assert: workflow_completed
      - action: verify_system_state
        assert: [health_scores_updated, metrics_recorded, audit_logged]

  # Error Handling and Recovery Tests
  - name: Error handling and system resilience
    description: Test system behavior under error conditions
    category: error_handling
    timeout: 240
    steps:
      - action: simulate_database_error
        type: connection_timeout
        assert: graceful_handling
      - action: simulate_ai_model_error
        type: generation_failure
        assert: fallback_triggered
      - action: simulate_resource_unavailability
        resource: qdrant
        assert: degraded_mode_operation
      - action: test_error_recovery
        scenarios: [reconnection, retry_logic, circuit_breaker]
        assert: recovery_successful

validation:
  # Resource Validation
  resources:
    - name: postgres
      checks: [connection, schema_loaded, seed_data_present]
      required: true
    - name: redis
      checks: [connection, channels_configured]
      required: true
    - name: qdrant
      checks: [connection, collections_created, health_check]
      required: true
    - name: ollama
      checks: [connection, models_loaded]
      required: true
    - name: n8n
      checks: [connection, workflows_deployed, execution_ready]
      required: true
    - name: windmill
      checks: [connection, app_deployed, flows_available]
      required: true
    - name: unstructured_io
      checks: [connection, document_processing_ready]
      required: false

  # API Endpoint Validation
  api_endpoints:
    windmill:
      - endpoint: /api/version
        method: GET
        expected_status: 200
      - endpoint: /api/w/document_manager/apps
        method: GET
        expected_status: 200
    n8n:
      - endpoint: /healthz
        method: GET
        expected_status: 200
      - endpoint: /api/v1/workflows
        method: GET
        expected_status: 200
    qdrant:
      - endpoint: /health
        method: GET
        expected_status: 200
      - endpoint: /collections
        method: GET
        expected_status: 200

  # Data Validation
  data_integrity:
    - name: referential_integrity
      description: Verify all foreign key relationships are maintained
      queries:
        - SELECT COUNT(*) FROM agents a LEFT JOIN applications app ON a.application_id = app.id WHERE app.id IS NULL
        - SELECT COUNT(*) FROM improvement_queue iq LEFT JOIN agents a ON iq.agent_id = a.id WHERE a.id IS NULL
      expected_results: [0, 0]
    
    - name: data_consistency
      description: Verify data consistency across tables
      queries:
        - SELECT COUNT(*) FROM applications WHERE active = true
        - SELECT COUNT(DISTINCT application_id) FROM agents WHERE enabled = true
      assert: consistent_counts

  # Performance Benchmarks
  performance:
    response_times:
      - operation: dashboard_load
        max_time: 3000ms
      - operation: agent_creation
        max_time: 2000ms
      - operation: improvement_processing
        max_time: 5000ms
    
    throughput:
      - operation: queue_processing
        min_items_per_minute: 10
      - operation: concurrent_agent_execution
        max_concurrent: 5

  # Security Validation
  security:
    - name: sql_injection_protection
      description: Test protection against SQL injection
      test_inputs: ["'; DROP TABLE applications; --", "1' OR '1'='1"]
      assert: inputs_sanitized
    
    - name: api_authentication
      description: Verify API endpoints require proper authentication
      endpoints: [/api/admin, /api/config]
      assert: unauthorized_rejected

# Cleanup procedures
cleanup:
  - name: Remove test data
    type: postgres
    action: delete_test_records
    tables: [applications, agents, improvement_queue, agent_templates]
    
  - name: Clear vector collections
    type: qdrant
    action: clear_collections
    collections: [documentation_embeddings, agent_memory]
    
  - name: Reset Redis channels
    type: redis
    action: flush_channels
    channels: [agent-notifications, improvement-queue]

# Reporting configuration
reporting:
  format: [json, html, junit]
  include_metrics: true
  include_logs: true
  output_directory: "test-results"
  retention_days: 30

# Test environment configuration
environment:
  variables:
    - POSTGRES_HOST: localhost
    - POSTGRES_PORT: 5433
    - POSTGRES_DB: document_manager
    - REDIS_HOST: localhost
    - REDIS_PORT: 6380
    - QDRANT_HOST: localhost
    - QDRANT_PORT: 6333
    - OLLAMA_HOST: localhost
    - OLLAMA_PORT: 11434
    - N8N_HOST: localhost
    - N8N_PORT: 5678
    - WINDMILL_HOST: localhost
    - WINDMILL_PORT: 5681
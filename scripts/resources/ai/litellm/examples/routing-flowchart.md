# LiteLLM Routing Decision Flow

```
ğŸ“¥ Request Comes In
         â”‚
         â–¼
ğŸ¤” Check Model Parameter
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
"auto"    Specific Model
 â”‚           â”‚
 â”‚           â–¼
 â”‚      ğŸ¯ Route directly to
 â”‚         specified model
 â”‚           â”‚
 â”‚           â–¼
 â”‚      âœ… Return response
 â”‚
 â–¼
ğŸ§® Cost-Based Routing
         â”‚
         â–¼
ğŸ’° Check Model Costs:
   â€¢ Ollama: $0.00
   â€¢ OpenAI: $0.002/1K
   â€¢ Anthropic: $0.003/1K
   â€¢ OpenRouter: varies
         â”‚
         â–¼
ğŸ”„ Try Models in Order:
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
ğŸ¦™ Try Ollama  âŒ Ollama Failed?
    â”‚              â”‚
    â–¼              â–¼
âœ… Success?    ğŸ”„ Try Next: OpenAI
    â”‚              â”‚
    â–¼              â–¼
ğŸ‰ Return      âœ… Success?
               â”‚
               â–¼
           ğŸ”„ Try Next: Anthropic
               â”‚
               â–¼
           âœ… Success?
               â”‚
               â–¼
           ğŸ”„ Try Next: OpenRouter
               â”‚
               â–¼
           ğŸ˜ All Failed
```

## Decision Factors

### 1. **API Key Availability**
```
âœ… Has OpenAI key â†’ Include in routing
âŒ No Anthropic key â†’ Skip Anthropic
âœ… Has OpenRouter key â†’ Use as fallback
```

### 2. **Model Health Status**
```
ğŸŸ¢ Ollama running â†’ Try first
ğŸ”´ OpenAI rate limited â†’ Skip temporarily
ğŸŸ¡ Anthropic slow â†’ Lower priority
```

### 3. **Cost Optimization**
```
FREE: Ollama models (always preferred)
$: Cheap API models (gpt-3.5-turbo)
$$: Expensive models (gpt-4, claude-opus)
```

### 4. **Fallback Configuration**
```yaml
# Custom fallback chains
fallbacks:
  - llama2-local: ["gpt-3.5-turbo", "claude-3-haiku"]
  - gpt-4: ["claude-3-sonnet", "gpt-3.5-turbo"]
```

## Example Routing Decisions

### Simple Task: "Hello"
```
1. ğŸ¦™ llama2-local (FREE) â†’ âœ… Success
   Cost: $0.00
```

### Complex Task: "Write a web app"
```
1. ğŸ¦™ llama2-local (FREE) â†’ âŒ Limited capability
2. ğŸ¤– gpt-3.5-turbo ($0.002) â†’ âœ… Success
   Cost: ~$0.01
```

### When Ollama is Down
```
1. ğŸ¦™ llama2-local â†’ âŒ Service unavailable
2. ğŸ¤– gpt-3.5-turbo â†’ âœ… Success
   Automatic failover worked!
```

### No API Keys Configured
```
1. ğŸ¦™ llama2-local (FREE) â†’ âœ… Only option available
   Falls back to local-only mode
```
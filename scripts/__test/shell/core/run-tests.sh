#!/usr/bin/env bash
# Optimized Test Runner - Replaces the slow original runner
# Runs all bats tests with proper timeouts and setup optimizations

set -euo pipefail

CORE_DIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
SHELL_DIR=$(dirname "${CORE_DIR}")
TESTS_DIR=$(dirname "${SHELL_DIR}")
SCRIPTS_DIR=$(dirname "${TESTS_DIR}")

# Source utilities
source "${SCRIPTS_DIR}/helpers/utils/exit_codes.sh"
source "${SCRIPTS_DIR}/helpers/utils/log.sh"

# Load simplified parallel runner if available
SIMPLE_PARALLEL_RUNNER_PATH="${TESTS_DIR}/lib/simple-parallel-runner.bash"
if [[ -f "$SIMPLE_PARALLEL_RUNNER_PATH" ]]; then
    source "$SIMPLE_PARALLEL_RUNNER_PATH"
    if simple_parallel::is_supported; then
        PARALLEL_RUNNER_AVAILABLE="true"
    else
        PARALLEL_RUNNER_AVAILABLE="false"
        log::warning "Parallel execution requirements not met"
    fi
else
    PARALLEL_RUNNER_AVAILABLE="false"
    log::warning "Parallel runner not found, parallel execution disabled"
fi

#######################################
# Configuration
#######################################

MODE="balanced"
MAX_FAILURES=50  # Increased from 20 to see more failures
TIMEOUT=60  # Increased from 45s to 60s base timeout

#######################################
# Test Discovery and Execution  
#######################################

# Determine appropriate timeout based on test type
get_test_timeout() {
    local test_file="$1"
    local default_timeout="$2"
    
    # Resource-intensive tests need more time - but with better logging
    if [[ "$test_file" =~ (api|models|install|process|docker|status|common)\.bats$ ]]; then
        echo $((default_timeout * 4))  # Reduced from 6x to 4x (240s) for debugging
    elif [[ "$test_file" =~ (manage|usage)\.bats$ ]]; then
        echo $((default_timeout * 3))  # Reduced from 4x to 3x (180s) for debugging
    elif [[ "$test_file" =~ (unstructured-io|comfyui|whisper|agent-s2|ollama) ]]; then
        echo $((default_timeout * 5))  # Reduced from 8x to 5x (300s) for debugging
    else
        echo $((default_timeout * 2))  # Keep 2x buffer for basic tests (120s)
    fi
}

run_single_test() {
    local test_file="$1"
    local timeout_duration="$2"
    
    local start_time=$(date +%s.%N)
    local temp_output=$(mktemp)
    
    # Log test start for debugging hangs
    echo "$(date '+%H:%M:%S') - Starting: $(basename "$test_file")" >&2
    
    # Run test with timeout
    if timeout "${timeout_duration}s" bats --tap "$test_file" > "$temp_output" 2>&1; then
        local exit_code=0
        echo "$(date '+%H:%M:%S') - Completed: $(basename "$test_file")" >&2
    else
        local exit_code=$?
        if [[ $exit_code -eq 124 ]]; then
            echo "$(date '+%H:%M:%S') - TIMEOUT: $(basename "$test_file") after ${timeout_duration}s" >&2
            log::error "‚è∞ $(basename "$test_file"): TIMEOUT (>${timeout_duration}s)"
            rm -f "$temp_output"
            return 1
        fi
        echo "$(date '+%H:%M:%S') - Failed: $(basename "$test_file") (exit $exit_code)" >&2
    fi
    
    # Calculate results
    local end_time=$(date +%s.%N)
    local duration
    duration=$(echo "scale=2; $end_time - $start_time" | bc -l 2>/dev/null || echo "0.00")
    
    local test_count=0
    local failure_count=0
    
    if [[ -f "$temp_output" ]]; then
        test_count=$(grep -c "^ok\|^not ok" "$temp_output" 2>/dev/null || echo "0")
        failure_count=$(grep -c "^not ok" "$temp_output" 2>/dev/null || echo "0")
        
        # Clean up any potential whitespace/newlines
        test_count=$(echo "$test_count" | tr -d '\n\r ')
        failure_count=$(echo "$failure_count" | tr -d '\n\r ')
        
        # Ensure they're valid numbers
        [[ "$test_count" =~ ^[0-9]+$ ]] || test_count=0
        [[ "$failure_count" =~ ^[0-9]+$ ]] || failure_count=0
    fi
    
    # Show result with enhanced error information
    if [[ $failure_count -gt 0 ]]; then
        log::error "‚ùå $(basename "$test_file"): ${duration}s, $failure_count/$test_count failed"
        
        # Show debugging information for failed tests if temp output exists
        if [[ -f "$temp_output" ]]; then
            # Extract first few failed test names for debugging
            local failed_tests
            failed_tests=$(grep "^not ok" "$temp_output" | head -3 | sed 's/^not ok [0-9]* //' || echo "")
            if [[ -n "$failed_tests" ]]; then
                echo "   Failed tests: $(echo "$failed_tests" | tr '\n' '; ' | sed 's/; $//')" >&2
            fi
            
            # Check for common error patterns
            if grep -q "Command not found" "$temp_output"; then
                echo "   ‚ö†Ô∏è  Contains 'Command not found' errors (function visibility issue)" >&2
            fi
            if grep -q "timeout" "$temp_output"; then
                echo "   ‚è∞ Contains timeout-related issues" >&2
            fi
            if grep -q "parse error" "$temp_output"; then
                echo "   üìù Contains JSON/parsing errors" >&2
            fi
        fi
        rm -f "$temp_output"
        return 1
    else
        log::success "‚úÖ $(basename "$test_file"): ${duration}s, $test_count tests passed"
        rm -f "$temp_output"
        return 0
    fi
}

main() {
    # Parse simple arguments
    local CHANGED_ONLY="no"
    local PARALLEL_JOBS="1"
    
    # Load configuration for default parallel jobs if available
    if command -v config::get >/dev/null 2>&1; then
        PARALLEL_JOBS=$(config::get "global.max_parallel_tests" "1")
    fi
    while [[ $# -gt 0 ]]; do
        case $1 in
            --timeout)
                TIMEOUT="$2"
                shift 2
                ;;
            --max-failures)
                MAX_FAILURES="$2"
                shift 2
                ;;
            --slow)
                TIMEOUT=60
                shift
                ;;
            --changed-only)
                CHANGED_ONLY="yes"
                shift
                ;;
            --parallel)
                PARALLEL_JOBS="$2"
                shift 2
                ;;
            *)
                break
                ;;
        esac
    done
    
    log::header "üß™ Optimized Test Runner"
    log::info "Base timeout: ${TIMEOUT}s (scaled up to 8x for AI services)"
    log::info "Max failures: $MAX_FAILURES"
    
    # Find test files with smart selection
    local -a test_files=()
    
    # Use provided test files if any arguments remain
    if [[ $# -gt 0 ]]; then
        log::info "üéØ Using provided test files: $*"
        for test_file in "$@"; do
            if [[ -f "$test_file" && "$test_file" =~ \.bats$ ]]; then
                test_files+=("$test_file")
            else
                log::warning "‚ö†Ô∏è  Test file not found or invalid: $test_file"
            fi
        done
    elif [[ "$CHANGED_ONLY" == "yes" ]]; then
        log::info "üîç Smart selection: Running tests for changed files only"
        
        # Get changed files from git
        local changed_files=()
        while IFS= read -r file; do
            changed_files+=("$file")
        done < <(git diff --name-only HEAD~1 HEAD 2>/dev/null || echo "")
        
        if [[ ${#changed_files[@]} -eq 0 ]]; then
            log::info "No changed files found, running all tests"
            CHANGED_ONLY="no"
        else
            log::info "Found ${#changed_files[@]} changed files"
            
            # Find related test files for changed files
            for changed_file in "${changed_files[@]}"; do
                # If it's a test file itself, include it
                if [[ "$changed_file" =~ \.bats$ ]]; then
                    if [[ -f "$SCRIPTS_DIR/../$changed_file" ]]; then
                        test_files+=("$SCRIPTS_DIR/../$changed_file")
                    fi
                fi
                
                # If it's a resource file, find related tests
                if [[ "$changed_file" =~ ^scripts/resources/ ]]; then
                    local resource_dir=$(dirname "$SCRIPTS_DIR/../$changed_file")
                    while IFS= read -r test_file; do
                        test_files+=("$test_file")
                    done < <(find "$resource_dir" -name "*.bats" -type f 2>/dev/null || true)
                fi
            done
            
            # Remove duplicates and sort
            readarray -t test_files < <(printf '%s\n' "${test_files[@]}" | sort -u)
        fi
    fi
    
    # Fallback to all test files if no smart selection or no changed files (but not if specific files were provided)
    if [[ "$CHANGED_ONLY" == "no" && ${#test_files[@]} -eq 0 && $# -eq 0 ]]; then
        while IFS= read -r test_file; do
            # Skip test helper utilities
            if [[ "$test_file" =~ __tests/helpers/ ]]; then
                continue
            fi
            test_files+=("$test_file")
        done < <(find "$SCRIPTS_DIR" -path "*/postgres/instances" -prune -o -name "*.bats" -type f -print 2>/dev/null | sort)
    fi
    
    log::info "üìÅ Found ${#test_files[@]} test files"
    if [[ "$PARALLEL_JOBS" -gt 1 ]]; then
        log::info "üöÄ Parallel execution: $PARALLEL_JOBS jobs"
    fi
    
    # Execute tests
    local start_time=$(date +%s.%N)
    local successful=0
    local failed=0
    
    # Choose execution mode: parallel or sequential
    if [[ "$PARALLEL_JOBS" -gt 1 && "$PARALLEL_RUNNER_AVAILABLE" == "true" && ${#test_files[@]} -gt 1 ]]; then
        log::info "üöÄ Using parallel execution with $PARALLEL_JOBS concurrent jobs"
        
        # Initialize simplified parallel runner
        simple_parallel::init "$PARALLEL_JOBS"
        
        # Run tests in parallel
        if simple_parallel::run_tests "${test_files[@]}"; then
            log::success "‚úÖ All parallel tests completed successfully"
        else
            log::error "‚ùå Some parallel tests failed"
        fi
        
        # Collect results from simplified parallel execution
        local results
        results=$(simple_parallel::get_results)
        successful=$(echo "$results" | cut -d: -f2)
        failed=$(echo "$results" | cut -d: -f4)
        
        # Ensure numeric values
        successful=${successful:-0}
        failed=${failed:-0}
        
    else
        # Sequential execution with intelligent timeouts
        if [[ "$PARALLEL_JOBS" -gt 1 ]]; then
            log::warning "‚ö†Ô∏è  Parallel execution requested but not available, falling back to sequential"
        fi
        log::info "üîÑ Using sequential execution"
        
        for test_file in "${test_files[@]}"; do
            local test_timeout=$(get_test_timeout "$test_file" "$TIMEOUT")
            if run_single_test "$test_file" "$test_timeout"; then
                successful=$((successful + 1))
            else
                failed=$((failed + 1))
                
                # Stop if too many failures
                if [[ $failed -ge $MAX_FAILURES ]]; then
                    log::warning "‚ö†Ô∏è  Stopping after $failed failures"
                    break
                fi
            fi
            
            # Enhanced progress reporting every 10 tests with estimated time
            local completed=$((successful + failed))
            if [[ $((completed % 10)) -eq 0 && $completed -gt 0 ]]; then
                local progress=$((completed * 100 / ${#test_files[@]}))
                local current_time=$(date +%s.%N)
                local elapsed=$((${current_time%.*} - ${start_time%.*}))
                local avg_per_test=$((elapsed / completed))
                local remaining=$((${#test_files[@]} - completed))
                local eta=$((remaining * avg_per_test))
                
                local eta_formatted=""
                if [[ $eta -gt 60 ]]; then
                    eta_formatted="~$((eta / 60))m$((eta % 60))s"
                else
                    eta_formatted="~${eta}s"
                fi
                
                log::info "üìä Progress: $completed/${#test_files[@]} ($progress%) - ‚úÖ$successful ‚ùå$failed - ETA: $eta_formatted"
            fi
        done
    fi
    
    # Enhanced progress reporting (for sequential mode only)
    # Note: Progress reporting was moved inside the sequential execution loop above
    
    # Results
    local end_time=$(date +%s.%N)
    local duration
    duration=$(echo "scale=2; $end_time - $start_time" | bc -l 2>/dev/null || echo "0.00")
    local total_executed=$((successful + failed))
    
    log::header "üìä Test Results"
    log::info "Duration: ${duration}s ($(echo "scale=1; $duration / 60" | bc -l)min)"
    log::info "Executed: $total_executed / ${#test_files[@]}"
    log::info "Successful: $successful"
    log::info "Failed: $failed"
    
    if [[ $total_executed -gt 0 ]]; then
        local success_rate=$((successful * 100 / total_executed))
        log::info "Success rate: ${success_rate}%"
        
        # Success if > 50% pass (realistic for this many tests)
        if [[ $success_rate -ge 50 ]]; then
            log::success "üéâ Test execution successful! (${success_rate}% ‚â• 50%)"
            exit 0
        else
            log::error "‚ùå Test execution failed (${success_rate}% < 50%)"
            exit 1
        fi
    else
        log::error "‚ùå No tests executed"
        exit 1
    fi
}

if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi